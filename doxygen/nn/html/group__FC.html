<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>NMSIS-NN: Fully-connected Layer Functions</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectlogo"><img alt="Logo" src="nmsis_logo_small.png"/></td>
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">NMSIS-NN
   &#160;<span id="projectnumber">Version 1.4.0</span>
   </div>
   <div id="projectbrief">NMSIS NN Software Library</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('group__FC.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="header">
  <div class="summary">
<a href="#groups">Modules</a> &#124;
<a href="#func-members">Functions</a>  </div>
  <div class="headertitle">
<div class="title">Fully-connected Layer Functions<div class="ingroups"><a class="el" href="group__Public.html">Public</a></div></div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="groups"></a>
Modules</h2></td></tr>
<tr class="memitem:group__GetBufferSizeFC"><td class="memItemLeft" align="right" valign="top">&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__GetBufferSizeFC.html">GetBufferSizeFC</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:gaba2bdf3a53bbdf29538a22fe9ebe22db"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#gaba2bdf3a53bbdf29538a22fe9ebe22db">riscv_batch_matmul_s16</a> (const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *ctx, const <a class="el" href="structnmsis__nn__bmm__params.html">nmsis_nn_bmm_params</a> *bmm_params, const <a class="el" href="structnmsis__nn__per__tensor__quant__params.html">nmsis_nn_per_tensor_quant_params</a> *quant_params, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *input_lhs_dims, const int16_t *input_lhs, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *input_rhs_dims, const int16_t *input_rhs, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *output_dims, int16_t *output)</td></tr>
<tr class="memdesc:gaba2bdf3a53bbdf29538a22fe9ebe22db"><td class="mdescLeft">&#160;</td><td class="mdescRight">Batch matmul function with 16 bit input and output.  <a href="group__FC.html#gaba2bdf3a53bbdf29538a22fe9ebe22db">More...</a><br /></td></tr>
<tr class="separator:gaba2bdf3a53bbdf29538a22fe9ebe22db"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga849ed33fbc301cd015616e4fde85431d"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#ga849ed33fbc301cd015616e4fde85431d">riscv_batch_matmul_s8</a> (const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *ctx, const <a class="el" href="structnmsis__nn__bmm__params.html">nmsis_nn_bmm_params</a> *bmm_params, const <a class="el" href="structnmsis__nn__per__tensor__quant__params.html">nmsis_nn_per_tensor_quant_params</a> *quant_params, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *input_lhs_dims, const int8_t *input_lhs, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *input_rhs_dims, const int8_t *input_rhs, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *output_dims, int8_t *output)</td></tr>
<tr class="memdesc:ga849ed33fbc301cd015616e4fde85431d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Batch matmul function with 8 bit input and output.  <a href="group__FC.html#ga849ed33fbc301cd015616e4fde85431d">More...</a><br /></td></tr>
<tr class="separator:ga849ed33fbc301cd015616e4fde85431d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga27a80b7911285b65cc2dfa58c7ab27af"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#ga27a80b7911285b65cc2dfa58c7ab27af">riscv_fully_connected_mat_q7_vec_q15</a> (const q15_t *pV, const q7_t *pM, const uint16_t dim_vec, const uint16_t num_of_rows, const uint16_t bias_shift, const uint16_t out_shift, const q7_t *bias, q15_t *pOut, q15_t *vec_buffer)</td></tr>
<tr class="memdesc:ga27a80b7911285b65cc2dfa58c7ab27af"><td class="mdescLeft">&#160;</td><td class="mdescRight">Mixed Q15-Q7 fully-connected layer function.  <a href="group__FC.html#ga27a80b7911285b65cc2dfa58c7ab27af">More...</a><br /></td></tr>
<tr class="separator:ga27a80b7911285b65cc2dfa58c7ab27af"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga3d267bd9dc04e6429dbbbc90b3e8a732"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#ga3d267bd9dc04e6429dbbbc90b3e8a732">riscv_fully_connected_mat_q7_vec_q15_opt</a> (const q15_t *pV, const q7_t *pM, const uint16_t dim_vec, const uint16_t num_of_rows, const uint16_t bias_shift, const uint16_t out_shift, const q7_t *bias, q15_t *pOut, q15_t *vec_buffer)</td></tr>
<tr class="memdesc:ga3d267bd9dc04e6429dbbbc90b3e8a732"><td class="mdescLeft">&#160;</td><td class="mdescRight">Mixed Q15-Q7 opt fully-connected layer function.  <a href="group__FC.html#ga3d267bd9dc04e6429dbbbc90b3e8a732">More...</a><br /></td></tr>
<tr class="separator:ga3d267bd9dc04e6429dbbbc90b3e8a732"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga9ab0181eb351ec0af6f244e2fbb3d3da"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#ga9ab0181eb351ec0af6f244e2fbb3d3da">riscv_fully_connected_per_channel_s8</a> (const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *ctx, const <a class="el" href="structnmsis__nn__fc__params.html">nmsis_nn_fc_params</a> *fc_params, const <a class="el" href="structnmsis__nn__per__channel__quant__params.html">nmsis_nn_per_channel_quant_params</a> *quant_params, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *input_dims, const int8_t *input_data, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *filter_dims, const int8_t *kernel, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *bias_dims, const int32_t *bias_data, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *output_dims, int8_t *output_data)</td></tr>
<tr class="memdesc:ga9ab0181eb351ec0af6f244e2fbb3d3da"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic s8 Fully Connected function using per channel quantization.  <a href="group__FC.html#ga9ab0181eb351ec0af6f244e2fbb3d3da">More...</a><br /></td></tr>
<tr class="separator:ga9ab0181eb351ec0af6f244e2fbb3d3da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga8e2653d16e373203c61c4d540115eb48"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#ga8e2653d16e373203c61c4d540115eb48">riscv_fully_connected_q15</a> (const q15_t *pV, const q15_t *pM, const uint16_t dim_vec, const uint16_t num_of_rows, const uint16_t bias_shift, const uint16_t out_shift, const q15_t *bias, q15_t *pOut, q15_t *vec_buffer)</td></tr>
<tr class="memdesc:ga8e2653d16e373203c61c4d540115eb48"><td class="mdescLeft">&#160;</td><td class="mdescRight">Q15 opt fully-connected layer function.  <a href="group__FC.html#ga8e2653d16e373203c61c4d540115eb48">More...</a><br /></td></tr>
<tr class="separator:ga8e2653d16e373203c61c4d540115eb48"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga9a7ea5eefbe1b2291f3a40c17b15701a"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#ga9a7ea5eefbe1b2291f3a40c17b15701a">riscv_fully_connected_q15_opt</a> (const q15_t *pV, const q15_t *pM, const uint16_t dim_vec, const uint16_t num_of_rows, const uint16_t bias_shift, const uint16_t out_shift, const q15_t *bias, q15_t *pOut, q15_t *vec_buffer)</td></tr>
<tr class="memdesc:ga9a7ea5eefbe1b2291f3a40c17b15701a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Q15 opt fully-connected layer function.  <a href="group__FC.html#ga9a7ea5eefbe1b2291f3a40c17b15701a">More...</a><br /></td></tr>
<tr class="separator:ga9a7ea5eefbe1b2291f3a40c17b15701a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gaa4862f80af70c6e75e1e5ec39a74cd27"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#gaa4862f80af70c6e75e1e5ec39a74cd27">riscv_fully_connected_q7</a> (const q7_t *pV, const q7_t *pM, const uint16_t dim_vec, const uint16_t num_of_rows, const uint16_t bias_shift, const uint16_t out_shift, const q7_t *bias, q7_t *pOut, q15_t *vec_buffer)</td></tr>
<tr class="memdesc:gaa4862f80af70c6e75e1e5ec39a74cd27"><td class="mdescLeft">&#160;</td><td class="mdescRight">Q7 basic fully-connected layer function.  <a href="group__FC.html#gaa4862f80af70c6e75e1e5ec39a74cd27">More...</a><br /></td></tr>
<tr class="separator:gaa4862f80af70c6e75e1e5ec39a74cd27"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga93cb07d98b15b282572efe601ab2fe5f"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#ga93cb07d98b15b282572efe601ab2fe5f">riscv_fully_connected_q7_opt</a> (const q7_t *pV, const q7_t *pM, const uint16_t dim_vec, const uint16_t num_of_rows, const uint16_t bias_shift, const uint16_t out_shift, const q7_t *bias, q7_t *pOut, q15_t *vec_buffer)</td></tr>
<tr class="memdesc:ga93cb07d98b15b282572efe601ab2fe5f"><td class="mdescLeft">&#160;</td><td class="mdescRight">Q7 opt fully-connected layer function.  <a href="group__FC.html#ga93cb07d98b15b282572efe601ab2fe5f">More...</a><br /></td></tr>
<tr class="separator:ga93cb07d98b15b282572efe601ab2fe5f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga330a1708818adb35cc96f04d987a3c87"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#ga330a1708818adb35cc96f04d987a3c87">riscv_fully_connected_s16</a> (const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *ctx, const <a class="el" href="structnmsis__nn__fc__params.html">nmsis_nn_fc_params</a> *fc_params, const <a class="el" href="structnmsis__nn__per__tensor__quant__params.html">nmsis_nn_per_tensor_quant_params</a> *quant_params, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *input_dims, const int16_t *input, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *filter_dims, const int8_t *kernel, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *bias_dims, const int64_t *bias, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *output_dims, int16_t *output)</td></tr>
<tr class="memdesc:ga330a1708818adb35cc96f04d987a3c87"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic s16 Fully Connected function.  <a href="group__FC.html#ga330a1708818adb35cc96f04d987a3c87">More...</a><br /></td></tr>
<tr class="separator:ga330a1708818adb35cc96f04d987a3c87"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gab3221ebdd3d36d73ffe55fed671e4df8"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#gab3221ebdd3d36d73ffe55fed671e4df8">riscv_fully_connected_s4</a> (const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *ctx, const <a class="el" href="structnmsis__nn__fc__params.html">nmsis_nn_fc_params</a> *fc_params, const <a class="el" href="structnmsis__nn__per__tensor__quant__params.html">nmsis_nn_per_tensor_quant_params</a> *quant_params, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *input_dims, const int8_t *input, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *filter_dims, const int8_t *kernel, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *bias_dims, const int32_t *bias, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *output_dims, int8_t *output)</td></tr>
<tr class="memdesc:gab3221ebdd3d36d73ffe55fed671e4df8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic s4 Fully Connected function.  <a href="group__FC.html#gab3221ebdd3d36d73ffe55fed671e4df8">More...</a><br /></td></tr>
<tr class="separator:gab3221ebdd3d36d73ffe55fed671e4df8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:gae98664e386670f48e499ef3e471cebbe"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#gae98664e386670f48e499ef3e471cebbe">riscv_fully_connected_s8</a> (const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *ctx, const <a class="el" href="structnmsis__nn__fc__params.html">nmsis_nn_fc_params</a> *fc_params, const <a class="el" href="structnmsis__nn__per__tensor__quant__params.html">nmsis_nn_per_tensor_quant_params</a> *quant_params, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *input_dims, const int8_t *input, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *filter_dims, const int8_t *kernel, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *bias_dims, const int32_t *bias, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *output_dims, int8_t *output)</td></tr>
<tr class="memdesc:gae98664e386670f48e499ef3e471cebbe"><td class="mdescLeft">&#160;</td><td class="mdescRight">Basic s8 Fully Connected function.  <a href="group__FC.html#gae98664e386670f48e499ef3e471cebbe">More...</a><br /></td></tr>
<tr class="separator:gae98664e386670f48e499ef3e471cebbe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga6f357c62e65caa61253aa312cd4f4ad3"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#ga6f357c62e65caa61253aa312cd4f4ad3">riscv_fully_connected_wrapper_s8</a> (const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *ctx, const <a class="el" href="structnmsis__nn__fc__params.html">nmsis_nn_fc_params</a> *fc_params, const <a class="el" href="structnmsis__nn__quant__params.html">nmsis_nn_quant_params</a> *quant_params, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *input_dims, const int8_t *input_data, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *filter_dims, const int8_t *filter_data, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *bias_dims, const int32_t *bias_data, const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *output_dims, int8_t *output_data)</td></tr>
<tr class="memdesc:ga6f357c62e65caa61253aa312cd4f4ad3"><td class="mdescLeft">&#160;</td><td class="mdescRight">s8 Fully Connected layer wrapper function  <a href="group__FC.html#ga6f357c62e65caa61253aa312cd4f4ad3">More...</a><br /></td></tr>
<tr class="separator:ga6f357c62e65caa61253aa312cd4f4ad3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga72911bd57efd90022f2312e34e0003bb"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#ga72911bd57efd90022f2312e34e0003bb">riscv_vector_sum_s8</a> (int32_t *vector_sum_buf, const int32_t vector_cols, const int32_t vector_rows, const int8_t *vector_data, const int32_t lhs_offset, const int32_t rhs_offset, const int32_t *bias_data)</td></tr>
<tr class="memdesc:ga72911bd57efd90022f2312e34e0003bb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculate the sum of each row in vector_data, multiply by lhs_offset and optionally add s32 bias_data.  <a href="group__FC.html#ga72911bd57efd90022f2312e34e0003bb">More...</a><br /></td></tr>
<tr class="separator:ga72911bd57efd90022f2312e34e0003bb"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ga62abbe7bf8f343c4152ef366c3d9f077"><td class="memItemLeft" align="right" valign="top"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="group__FC.html#ga62abbe7bf8f343c4152ef366c3d9f077">riscv_vector_sum_s8_s64</a> (int64_t *vector_sum_buf, const int32_t vector_cols, const int32_t vector_rows, const int8_t *vector_data, const int32_t lhs_offset, const int64_t *bias_data)</td></tr>
<tr class="memdesc:ga62abbe7bf8f343c4152ef366c3d9f077"><td class="mdescLeft">&#160;</td><td class="mdescRight">Calculate the sum of each row in vector_data, multiply by lhs_offset and optionally add s64 bias_data.  <a href="group__FC.html#ga62abbe7bf8f343c4152ef366c3d9f077">More...</a><br /></td></tr>
<tr class="separator:ga62abbe7bf8f343c4152ef366c3d9f077"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<p>Collection of fully-connected and matrix multiplication functions.</p>
<p>Fully-connected layer is basically a matrix-vector multiplication with bias. The matrix is the weights and the input/output vectors are the activation values. Supported {weight, activation} precisions include {8-bit, 8-bit} and {8-bit, 16-bit} </p>
<h2 class="groupheader">Function Documentation</h2>
<a id="gaba2bdf3a53bbdf29538a22fe9ebe22db"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaba2bdf3a53bbdf29538a22fe9ebe22db">&#9670;&nbsp;</a></span>riscv_batch_matmul_s16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_batch_matmul_s16 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *&#160;</td>
          <td class="paramname"><em>ctx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__bmm__params.html">nmsis_nn_bmm_params</a> *&#160;</td>
          <td class="paramname"><em>bmm_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__per__tensor__quant__params.html">nmsis_nn_per_tensor_quant_params</a> *&#160;</td>
          <td class="paramname"><em>quant_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>input_lhs_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t *&#160;</td>
          <td class="paramname"><em>input_lhs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>input_rhs_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t *&#160;</td>
          <td class="paramname"><em>input_rhs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>output_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int16_t *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Batch matmul function with 16 bit input and output. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">ctx</td><td>Temporary scratch buffer The caller is expected to clear the buffer, if applicable, for security reasons. Optional function <a class="el" href="group__GetBufferSizeFC.html#gad6f87a614339280578e030ff6599ec2d" title="Get size of additional buffer required by riscv_fully_connected_s8(). See also riscv_vector_sum_s8,...">riscv_fully_connected_s8_get_buffer_size()</a> provides the buffer size if an additional buffer is required. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bmm_params</td><td>Batch matmul Parameters Adjoint flags are currently unused. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">quant_params</td><td>Quantization parameters </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_lhs_dims</td><td>Input lhs tensor dimensions. This should be NHWC where LHS.C = RHS.C </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_lhs</td><td>Pointer to input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_rhs_dims</td><td>Input lhs tensor dimensions. This is expected to be transposed so should be NHWC where LHS.C = RHS.C </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_rhs</td><td>Pointer to transposed input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output_dims</td><td>Output tensor dimensions </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Pointer to the output tensor</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns <code>RISCV_NMSIS_NN_SUCCESS</code></dd></dl>
<ol type="1">
<li>Supported framework: TensorFlow Lite Micro</li>
<li>Performs row * row matrix multiplication with the RHS transposed. </li>
</ol>

</div>
</div>
<a id="ga849ed33fbc301cd015616e4fde85431d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga849ed33fbc301cd015616e4fde85431d">&#9670;&nbsp;</a></span>riscv_batch_matmul_s8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_batch_matmul_s8 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *&#160;</td>
          <td class="paramname"><em>ctx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__bmm__params.html">nmsis_nn_bmm_params</a> *&#160;</td>
          <td class="paramname"><em>bmm_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__per__tensor__quant__params.html">nmsis_nn_per_tensor_quant_params</a> *&#160;</td>
          <td class="paramname"><em>quant_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>input_lhs_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>input_lhs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>input_rhs_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>input_rhs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>output_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>output</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Batch matmul function with 8 bit input and output. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">ctx</td><td>Temporary scratch buffer The caller is expected to clear the buffer, if applicable, for security reasons. Optional function <a class="el" href="group__GetBufferSizeFC.html#gad6f87a614339280578e030ff6599ec2d" title="Get size of additional buffer required by riscv_fully_connected_s8(). See also riscv_vector_sum_s8,...">riscv_fully_connected_s8_get_buffer_size()</a> provides the buffer size if an additional buffer is required. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bmm_params</td><td>Batch matmul Parameters Adjoint flags are currently unused. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">quant_params</td><td>Quantization parameters </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_lhs_dims</td><td>Input lhs tensor dimensions. This should be NHWC where lhs C = rhs C </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_lhs</td><td>Pointer to input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_rhs_dims</td><td>Input lhs tensor dimensions. This is expected to be transposed so should be NHWC where lhs C = rhs C </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_rhs</td><td>Pointer to transposed input tensor </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output_dims</td><td>Output tensor dimensions </td></tr>
    <tr><td class="paramdir">[out]</td><td class="paramname">output</td><td>Pointer to the output tensor</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns <code>RISCV_NMSIS_NN_SUCCESS</code></dd></dl>
<ol type="1">
<li>Supported framework: TensorFlow Lite Micro</li>
<li>Performs row * row matrix multiplication with the RHS transposed. </li>
</ol>

</div>
</div>
<a id="ga27a80b7911285b65cc2dfa58c7ab27af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga27a80b7911285b65cc2dfa58c7ab27af">&#9670;&nbsp;</a></span>riscv_fully_connected_mat_q7_vec_q15()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_fully_connected_mat_q7_vec_q15 </td>
          <td>(</td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>pV</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>pM</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dim_vec</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>num_of_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>pOut</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>vec_buffer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Mixed Q15-Q7 fully-connected layer function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">pV</td><td>pointer to input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pM</td><td>pointer to matrix weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dim_vec</td><td>length of the vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_of_rows</td><td>number of rows in weight matrix </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_shift</td><td>amount of left-shift for bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>amount of right-shift for output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer to bias </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">pOut</td><td>pointer to output vector </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">vec_buffer</td><td>pointer to buffer space for input </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns <code>RISCV_NMSIS_NN_SUCCESS</code></dd></dl>
<p><b>Buffer size:</b></p>
<p>vec_buffer size: 0</p>
<p>Q7_Q15 version of the fully connected layer</p>
<p>Weights are in q7_t and Activations are in q15_t </p>

</div>
</div>
<a id="ga3d267bd9dc04e6429dbbbc90b3e8a732"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga3d267bd9dc04e6429dbbbc90b3e8a732">&#9670;&nbsp;</a></span>riscv_fully_connected_mat_q7_vec_q15_opt()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_fully_connected_mat_q7_vec_q15_opt </td>
          <td>(</td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>pV</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>pM</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dim_vec</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>num_of_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>pOut</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>vec_buffer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Mixed Q15-Q7 opt fully-connected layer function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">pV</td><td>pointer to input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pM</td><td>pointer to matrix weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dim_vec</td><td>length of the vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_of_rows</td><td>number of rows in weight matrix </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_shift</td><td>amount of left-shift for bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>amount of right-shift for output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer to bias </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">pOut</td><td>pointer to output vector </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">vec_buffer</td><td>pointer to buffer space for input </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns <code>RISCV_NMSIS_NN_SUCCESS</code></dd></dl>
<p><b>Buffer size:</b></p>
<p>vec_buffer size: 0</p>
<p>Q7_Q15 version of the fully connected layer</p>
<p>Weights are in q7_t and Activations are in q15_t</p>
<p>Limitation: x4 version requires weight reordering to work</p>
<p>Here we use only one pointer to read 4 rows in the weight matrix. So if the original q7_t matrix looks like this:</p>
<p>| a11 | a12 | a13 | a14 | a15 | a16 | a17 |</p>
<p>| a21 | a22 | a23 | a24 | a25 | a26 | a27 |</p>
<p>| a31 | a32 | a33 | a34 | a35 | a36 | a37 |</p>
<p>| a41 | a42 | a43 | a44 | a45 | a46 | a47 |</p>
<p>| a51 | a52 | a53 | a54 | a55 | a56 | a57 |</p>
<p>| a61 | a62 | a63 | a64 | a65 | a66 | a67 |</p>
<p>We operates on multiple-of-4 rows, so the first four rows becomes</p>
<p>| a11 | a21 | a12 | a22 | a31 | a41 | a32 | a42 |</p>
<p>| a13 | a23 | a14 | a24 | a33 | a43 | a34 | a44 |</p>
<p>| a15 | a25 | a16 | a26 | a35 | a45 | a36 | a46 |</p>
<p>The column left over will be in-order. which is: | a17 | a27 | a37 | a47 |</p>
<p>For the left-over rows, we do 1x1 computation, so the data remains as its original order.</p>
<p>So the stored weight matrix looks like this:</p>
<p>| a11 | a21 | a12 | a22 | a31 | a41 |</p>
<p>| a32 | a42 | a13 | a23 | a14 | a24 |</p>
<p>| a33 | a43 | a34 | a44 | a15 | a25 |</p>
<p>| a16 | a26 | a35 | a45 | a36 | a46 |</p>
<p>| a17 | a27 | a37 | a47 | a51 | a52 |</p>
<p>| a53 | a54 | a55 | a56 | a57 | a61 |</p>
<p>| a62 | a63 | a64 | a65 | a66 | a67 | </p>

</div>
</div>
<a id="ga9ab0181eb351ec0af6f244e2fbb3d3da"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga9ab0181eb351ec0af6f244e2fbb3d3da">&#9670;&nbsp;</a></span>riscv_fully_connected_per_channel_s8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_fully_connected_per_channel_s8 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *&#160;</td>
          <td class="paramname"><em>ctx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__fc__params.html">nmsis_nn_fc_params</a> *&#160;</td>
          <td class="paramname"><em>fc_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__per__channel__quant__params.html">nmsis_nn_per_channel_quant_params</a> *&#160;</td>
          <td class="paramname"><em>quant_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>input_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>input_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>filter_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>filter_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>bias_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>output_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>output_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Basic s8 Fully Connected function using per channel quantization. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">ctx</td><td>Function context (e.g. temporary buffer). Check the function definition file to see if an additional buffer is required. Optional function {API}_get_buffer_size() provides the buffer size if an additional buffer is required. The caller is expected to clear the buffer, if applicable, for security reasons. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">fc_params</td><td>Fully Connected layer parameters. Range of fc_params-&gt;input_offset : [-127, 128] fc_params-&gt;filter_offset : 0 Range of fc_params-&gt;output_offset : [-128, 127] </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">quant_params</td><td>Per-channel quantization info. It contains the multiplier and shift values to be applied to each output channel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_dims</td><td>Input (activation) tensor dimensions. Format: [N, H, W, C_IN] Input dimension is taken as Nx(H * W * C_IN) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_data</td><td>Input (activation) data pointer. Data type: int8 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filter_dims</td><td>Two dimensional filter dimensions. Format: [N, C] N : accumulation depth and equals (H * W * C_IN) from input_dims C : output depth and equals C_OUT in output_dims H &amp; W : Not used </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filter_data</td><td>Filter data pointer. Data type: int8 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_dims</td><td>Bias tensor dimensions. Format: [C_OUT] N, H, W : Not used </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_data</td><td>Bias data pointer. Data type: int32 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output_dims</td><td>Output tensor dimensions. Format: [N, C_OUT] N : Batches C_OUT : Output depth H &amp; W : Not used. </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">output_data</td><td>Output data pointer. Data type: int8</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns either <code>RISCV_NMSIS_NN_ARG_ERROR</code> if argument constraints fail. or, <code>RISCV_NMSIS_NN_SUCCESS</code> on successful completion.</dd></dl>
<ul>
<li>Supported framework: TensorFlow Lite </li>
</ul>

</div>
</div>
<a id="ga8e2653d16e373203c61c4d540115eb48"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga8e2653d16e373203c61c4d540115eb48">&#9670;&nbsp;</a></span>riscv_fully_connected_q15()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_fully_connected_q15 </td>
          <td>(</td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>pV</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>pM</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dim_vec</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>num_of_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>pOut</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>vec_buffer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Q15 opt fully-connected layer function. </p>
<p>Q15 basic fully-connected layer function.</p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">pV</td><td>pointer to input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pM</td><td>pointer to matrix weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dim_vec</td><td>length of the vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_of_rows</td><td>number of rows in weight matrix </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_shift</td><td>amount of left-shift for bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>amount of right-shift for output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer to bias </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">pOut</td><td>pointer to output vector </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">vec_buffer</td><td>pointer to buffer space for input </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns <code>RISCV_NMSIS_NN_SUCCESS</code></dd></dl>
<p><b>Buffer size:</b></p>
<p>vec_buffer size: 0 </p>

</div>
</div>
<a id="ga9a7ea5eefbe1b2291f3a40c17b15701a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga9a7ea5eefbe1b2291f3a40c17b15701a">&#9670;&nbsp;</a></span>riscv_fully_connected_q15_opt()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_fully_connected_q15_opt </td>
          <td>(</td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>pV</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>pM</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dim_vec</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>num_of_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q15_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>pOut</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>vec_buffer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Q15 opt fully-connected layer function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">pV</td><td>pointer to input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pM</td><td>pointer to matrix weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dim_vec</td><td>length of the vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_of_rows</td><td>number of rows in weight matrix </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_shift</td><td>amount of left-shift for bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>amount of right-shift for output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer to bias </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">pOut</td><td>pointer to output vector </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">vec_buffer</td><td>pointer to buffer space for input </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns <code>RISCV_NMSIS_NN_SUCCESS</code></dd></dl>
<p><b>Buffer size:</b></p>
<p>vec_buffer size: 0</p>
<p>Here we use only one pointer to read 4 rows in the weight matrix. So if the original matrix looks like this:</p>
<p>| a11 | a12 | a13 |</p>
<p>| a21 | a22 | a23 |</p>
<p>| a31 | a32 | a33 |</p>
<p>| a41 | a42 | a43 |</p>
<p>| a51 | a52 | a53 |</p>
<p>| a61 | a62 | a63 |</p>
<p>We operates on multiple-of-4 rows, so the first four rows becomes</p>
<p>| a11 | a12 | a21 | a22 | a31 | a32 | a41 | a42 |</p>
<p>| a13 | a23 | a33 | a43 |</p>
<p>Remaining rows are kept the same original order.</p>
<p>So the stored weight matrix looks like this:</p>
<p>| a11 | a12 | a21 | a22 | a31 | a32 | a41 | a42 |</p>
<p>| a13 | a23 | a33 | a43 | a51 | a52 | a53 | a61 |</p>
<p>| a62 | a63 | </p>

</div>
</div>
<a id="gaa4862f80af70c6e75e1e5ec39a74cd27"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gaa4862f80af70c6e75e1e5ec39a74cd27">&#9670;&nbsp;</a></span>riscv_fully_connected_q7()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_fully_connected_q7 </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>pV</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>pM</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dim_vec</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>num_of_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>pOut</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>vec_buffer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Q7 basic fully-connected layer function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">pV</td><td>pointer to input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pM</td><td>pointer to matrix weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dim_vec</td><td>length of the vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_of_rows</td><td>number of rows in weight matrix </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_shift</td><td>amount of left-shift for bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>amount of right-shift for output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer to bias </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">pOut</td><td>pointer to output vector </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">vec_buffer</td><td>pointer to buffer space for input </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns <code>RISCV_NMSIS_NN_SUCCESS</code></dd></dl>
<p><b>Buffer size:</b></p>
<p>vec_buffer size: dim_vec</p>
<p>This basic function is designed to work with regular weight matrix without interleaving. </p>

</div>
</div>
<a id="ga93cb07d98b15b282572efe601ab2fe5f"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga93cb07d98b15b282572efe601ab2fe5f">&#9670;&nbsp;</a></span>riscv_fully_connected_q7_opt()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_fully_connected_q7_opt </td>
          <td>(</td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>pV</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>pM</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>dim_vec</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>num_of_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>bias_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const uint16_t&#160;</td>
          <td class="paramname"><em>out_shift</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const q7_t *&#160;</td>
          <td class="paramname"><em>bias</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q7_t *&#160;</td>
          <td class="paramname"><em>pOut</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">q15_t *&#160;</td>
          <td class="paramname"><em>vec_buffer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Q7 opt fully-connected layer function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in]</td><td class="paramname">pV</td><td>pointer to input vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">pM</td><td>pointer to matrix weights </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">dim_vec</td><td>length of the vector </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">num_of_rows</td><td>number of rows in weight matrix </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_shift</td><td>amount of left-shift for bias </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">out_shift</td><td>amount of right-shift for output </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias</td><td>pointer to bias </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">pOut</td><td>pointer to output vector </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">vec_buffer</td><td>pointer to buffer space for input </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns <code>RISCV_NMSIS_NN_SUCCESS</code></dd></dl>
<p><b>Buffer size:</b></p>
<p>vec_buffer size: dim_vec</p>
<p>This opt function is designed to work with interleaved weight matrix. The vector input is assumed in q7_t format, we call riscv_q7_to_q15_no_shift_shuffle function to expand into q15_t format with certain weight re-ordering, refer to the function comments for more details. Here we use only one pointer to read 4 rows in the weight matrix. So if the original q7_t matrix looks like this:</p>
<p>| a11 | a12 | a13 | a14 | a15 | a16 | a17 |</p>
<p>| a21 | a22 | a23 | a24 | a25 | a26 | a27 |</p>
<p>| a31 | a32 | a33 | a34 | a35 | a36 | a37 |</p>
<p>| a41 | a42 | a43 | a44 | a45 | a46 | a47 |</p>
<p>| a51 | a52 | a53 | a54 | a55 | a56 | a57 |</p>
<p>| a61 | a62 | a63 | a64 | a65 | a66 | a67 |</p>
<p>We operates on multiple-of-4 rows, so the first four rows becomes</p>
<p>| a11 | a21 | a13 | a23 | a31 | a41 | a33 | a43 |</p>
<p>| a12 | a22 | a14 | a24 | a32 | a42 | a34 | a44 |</p>
<p>| a15 | a25 | a35 | a45 | a16 | a26 | a36 | a46 |</p>
<p>So within the kernel, we first read the re-ordered vector in as:</p>
<p>| b1 | b3 | and | b2 | b4 |</p>
<p>the four q31_t weights will look like</p>
<p>| a11 | a13 |, | a21 | a23 |, | a31 | a33 |, | a41 | a43 |</p>
<p>| a12 | a14 |, | a22 | a24 |, | a32 | a34 |, | a42 | a44 |</p>
<p>The column left over will be in-order. which is:</p>
<p>| a17 | a27 | a37 | a47 |</p>
<p>For the left-over rows, we do 1x1 computation, so the data remains as its original order.</p>
<p>So the stored weight matrix looks like this:</p>
<p>| a11 | a21 | a13 | a23 | a31 | a41 |</p>
<p>| a33 | a43 | a12 | a22 | a14 | a24 |</p>
<p>| a32 | a42 | a34 | a44 | a15 | a25 |</p>
<p>| a35 | a45 | a16 | a26 | a36 | a46 |</p>
<p>| a17 | a27 | a37 | a47 | a51 | a52 |</p>
<p>| a53 | a54 | a55 | a56 | a57 | a61 |</p>
<p>| a62 | a63 | a64 | a65 | a66 | a67 | </p>

</div>
</div>
<a id="ga330a1708818adb35cc96f04d987a3c87"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga330a1708818adb35cc96f04d987a3c87">&#9670;&nbsp;</a></span>riscv_fully_connected_s16()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_fully_connected_s16 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *&#160;</td>
          <td class="paramname"><em>ctx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__fc__params.html">nmsis_nn_fc_params</a> *&#160;</td>
          <td class="paramname"><em>fc_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__per__tensor__quant__params.html">nmsis_nn_per_tensor_quant_params</a> *&#160;</td>
          <td class="paramname"><em>quant_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>input_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int16_t *&#160;</td>
          <td class="paramname"><em>input_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>filter_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>filter_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>bias_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t *&#160;</td>
          <td class="paramname"><em>bias_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>output_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int16_t *&#160;</td>
          <td class="paramname"><em>output_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Basic s16 Fully Connected function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">ctx</td><td>Function context (e.g. temporary buffer). Check the function definition file to see if an additional buffer is required. Optional function {API}_get_buffer_size() provides the buffer size if an additional buffer is required. The caller is expected to clear the buffer, if applicable, for security reasons. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">fc_params</td><td>Fully Connected layer parameters. fc_params-&gt;input_offset : 0 fc_params-&gt;filter_offset : 0 fc_params-&gt;output_offset : 0 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">quant_params</td><td>Per-tensor quantization info. It contains the multiplier and shift value to be applied to the output tensor. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_dims</td><td>Input (activation) tensor dimensions. Format: [N, H, W, C_IN] Input dimension is taken as Nx(H * W * C_IN) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_data</td><td>Input (activation) data pointer. Data type: int16 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filter_dims</td><td>Two dimensional filter dimensions. Format: [N, C] N : accumulation depth and equals (H * W * C_IN) from input_dims C : output depth and equals C_OUT in output_dims H &amp; W : Not used </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filter_data</td><td>Filter data pointer. Data type: int8 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_dims</td><td>Bias tensor dimensions. Format: [C_OUT] N, H, W : Not used </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_data</td><td>Bias data pointer. Data type: int64 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output_dims</td><td>Output tensor dimensions. Format: [N, C_OUT] N : Batches C_OUT : Output depth H &amp; W : Not used. </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">output_data</td><td>Output data pointer. Data type: int16 </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns <code>RISCV_NMSIS_NN_SUCCESS</code></dd></dl>
<ul>
<li>Supported framework: TensorFlow Lite </li>
</ul>

</div>
</div>
<a id="gab3221ebdd3d36d73ffe55fed671e4df8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gab3221ebdd3d36d73ffe55fed671e4df8">&#9670;&nbsp;</a></span>riscv_fully_connected_s4()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_fully_connected_s4 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *&#160;</td>
          <td class="paramname"><em>ctx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__fc__params.html">nmsis_nn_fc_params</a> *&#160;</td>
          <td class="paramname"><em>fc_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__per__tensor__quant__params.html">nmsis_nn_per_tensor_quant_params</a> *&#160;</td>
          <td class="paramname"><em>quant_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>input_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>input_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>filter_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>filter_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>bias_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>output_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>output_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Basic s4 Fully Connected function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">ctx</td><td>Function context (e.g. temporary buffer). Check the function definition file to see if an additional buffer is required. Optional function {API}_get_buffer_size() provides the buffer size if an additional buffer is required. The caller is expected to clear the buffer ,if applicable, for security reasons. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">fc_params</td><td>Fully Connected layer parameters. Range of fc_params-&gt;input_offset : [-127, 128] fc_params-&gt;filter_offset : 0 Range of fc_params-&gt;output_offset : [-128, 127] </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">quant_params</td><td>Per-tensor quantization info. It contains the multiplier and shift value to be applied to the output tensor. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_dims</td><td>Input (activation) tensor dimensions. Format: [N, H, W, C_IN] Input dimension is taken as Nx(H * W * C_IN) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_data</td><td>Input (activation) data pointer. Data type: int8 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filter_dims</td><td>Two dimensional filter dimensions. Format: [N, C] N : accumulation depth and equals (H * W * C_IN) from input_dims C : output depth and equals C_OUT in output_dims H &amp; W : Not used </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filter_data</td><td>Filter data pointer. Data type: int8_t packed 4-bit weights, e.g four sequential weights [0x1, 0x2, 0x3, 0x4] packed as [0x21, 0x43]. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_dims</td><td>Bias tensor dimensions. Format: [C_OUT] N, H, W : Not used </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_data</td><td>Bias data pointer. Data type: int32 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output_dims</td><td>Output tensor dimensions. Format: [N, C_OUT] N : Batches C_OUT : Output depth H &amp; W : Not used. </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">output_data</td><td>Output data pointer. Data type: int8 </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns <code>RISCV_NMSIS_NN_SUCCESS</code></dd></dl>
<ul>
<li>Supported framework: TensorFlow Lite </li>
</ul>

</div>
</div>
<a id="gae98664e386670f48e499ef3e471cebbe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#gae98664e386670f48e499ef3e471cebbe">&#9670;&nbsp;</a></span>riscv_fully_connected_s8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_fully_connected_s8 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *&#160;</td>
          <td class="paramname"><em>ctx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__fc__params.html">nmsis_nn_fc_params</a> *&#160;</td>
          <td class="paramname"><em>fc_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__per__tensor__quant__params.html">nmsis_nn_per_tensor_quant_params</a> *&#160;</td>
          <td class="paramname"><em>quant_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>input_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>input_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>filter_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>filter_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>bias_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>output_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>output_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Basic s8 Fully Connected function. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">ctx</td><td>Function context (e.g. temporary buffer). Check the function definition file to see if an additional buffer is required. Optional function {API}_get_buffer_size() provides the buffer size if an additional buffer is required. The caller is expected to clear the buffer, if applicable, for security reasons. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">fc_params</td><td>Fully Connected layer parameters. Range of fc_params-&gt;input_offset : [-127, 128] fc_params-&gt;filter_offset : 0 Range of fc_params-&gt;output_offset : [-128, 127] </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">quant_params</td><td>Per-tensor quantization info. It contains the multiplier and shift value to be applied to the output tensor. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_dims</td><td>Input (activation) tensor dimensions. Format: [N, H, W, C_IN] Input dimension is taken as Nx(H * W * C_IN) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_data</td><td>Input (activation) data pointer. Data type: int8 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filter_dims</td><td>Two dimensional filter dimensions. Format: [N, C] N : accumulation depth and equals (H * W * C_IN) from input_dims C : output depth and equals C_OUT in output_dims H &amp; W : Not used </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filter_data</td><td>Filter data pointer. Data type: int8 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_dims</td><td>Bias tensor dimensions. Format: [C_OUT] N, H, W : Not used </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_data</td><td>Bias data pointer. Data type: int32 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output_dims</td><td>Output tensor dimensions. Format: [N, C_OUT] N : Batches C_OUT : Output depth H &amp; W : Not used. </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">output_data</td><td>Output data pointer. Data type: int8</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns either <code>RISCV_NMSIS_NN_ARG_ERROR</code> if argument constraints fail. or, <code>RISCV_NMSIS_NN_SUCCESS</code> on successful completion.</dd></dl>
<ul>
<li>Supported framework: TensorFlow Lite </li>
</ul>

</div>
</div>
<a id="ga6f357c62e65caa61253aa312cd4f4ad3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga6f357c62e65caa61253aa312cd4f4ad3">&#9670;&nbsp;</a></span>riscv_fully_connected_wrapper_s8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_fully_connected_wrapper_s8 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__context.html">nmsis_nn_context</a> *&#160;</td>
          <td class="paramname"><em>ctx</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__fc__params.html">nmsis_nn_fc_params</a> *&#160;</td>
          <td class="paramname"><em>fc_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__quant__params.html">nmsis_nn_quant_params</a> *&#160;</td>
          <td class="paramname"><em>quant_params</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>input_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>input_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>filter_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>filter_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>bias_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="structnmsis__nn__dims.html">nmsis_nn_dims</a> *&#160;</td>
          <td class="paramname"><em>output_dims</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int8_t *&#160;</td>
          <td class="paramname"><em>output_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>s8 Fully Connected layer wrapper function </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">ctx</td><td>Function context (e.g. temporary buffer). Check the function definition file to see if an additional buffer is required. Optional function {API}_get_buffer_size() provides the buffer size if an additional buffer is required. The caller is expected to clear the buffer, if applicable, for security reasons. </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">fc_params</td><td>Fully Connected layer parameters. Range of fc_params-&gt;input_offset : [-127, 128] fc_params-&gt;filter_offset : 0 Range of fc_params-&gt;output_offset : [-128, 127] </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">quant_params</td><td>Per-channel or per-tensor quantization info. Check struct defintion for details. It contains the multiplier and shift value(s) to be applied to each output channel </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_dims</td><td>Input (activation) tensor dimensions. Format: [N, H, W, C_IN] Input dimension is taken as Nx(H * W * C_IN) </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">input_data</td><td>Input (activation) data pointer. Data type: int8 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filter_dims</td><td>Two dimensional filter dimensions. Format: [N, C] N : accumulation depth and equals (H * W * C_IN) from input_dims C : output depth and equals C_OUT in output_dims H &amp; W : Not used </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">filter_data</td><td>Filter data pointer. Data type: int8 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_dims</td><td>Bias tensor dimensions. Format: [C_OUT] N, H, W : Not used </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_data</td><td>Bias data pointer. Data type: int32 </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">output_dims</td><td>Output tensor dimensions. Format: [N, C_OUT] N : Batches C_OUT : Output depth H &amp; W : Not used. </td></tr>
    <tr><td class="paramdir">[in,out]</td><td class="paramname">output_data</td><td>Output data pointer. Data type: int8</td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns either <code>RISCV_NMSIS_NN_ARG_ERROR</code> if argument constraints fail. or, <code>RISCV_NMSIS_NN_SUCCESS</code> on successful completion.</dd></dl>
<ul>
<li>Supported framework: TensorFlow Lite </li>
</ul>

</div>
</div>
<a id="ga72911bd57efd90022f2312e34e0003bb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga72911bd57efd90022f2312e34e0003bb">&#9670;&nbsp;</a></span>riscv_vector_sum_s8()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_vector_sum_s8 </td>
          <td>(</td>
          <td class="paramtype">int32_t *&#160;</td>
          <td class="paramname"><em>vector_sum_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>vector_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>vector_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>vector_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>lhs_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>rhs_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t *&#160;</td>
          <td class="paramname"><em>bias_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculate the sum of each row in vector_data, multiply by lhs_offset and optionally add s32 bias_data. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">vector_sum_buf</td><td>Buffer for vector sums </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">vector_cols</td><td>Number of vector columns </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">vector_rows</td><td>Number of vector rows </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">vector_data</td><td>Vector of weigths data </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">lhs_offset</td><td>Constant multiplied with each sum </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">rhs_offset</td><td>Constant added to each vector element before sum </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_data</td><td>Vector of bias data, added to each sum. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns <code>RISCV_NMSIS_NN_SUCCESS</code> - Successful operation </dd></dl>

</div>
</div>
<a id="ga62abbe7bf8f343c4152ef366c3d9f077"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ga62abbe7bf8f343c4152ef366c3d9f077">&#9670;&nbsp;</a></span>riscv_vector_sum_s8_s64()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="group__genPubTypes.html#gabee189e6614258574db704417ef44d71">riscv_nmsis_nn_status</a> riscv_vector_sum_s8_s64 </td>
          <td>(</td>
          <td class="paramtype">int64_t *&#160;</td>
          <td class="paramname"><em>vector_sum_buf</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>vector_cols</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>vector_rows</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int8_t *&#160;</td>
          <td class="paramname"><em>vector_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int32_t&#160;</td>
          <td class="paramname"><em>lhs_offset</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const int64_t *&#160;</td>
          <td class="paramname"><em>bias_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Calculate the sum of each row in vector_data, multiply by lhs_offset and optionally add s64 bias_data. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramdir">[in,out]</td><td class="paramname">vector_sum_buf</td><td>Buffer for vector sums </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">vector_cols</td><td>Number of vector columns </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">vector_rows</td><td>Number of vector rows </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">vector_data</td><td>Vector of weigths data </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">lhs_offset</td><td>Constant multiplied with each sum </td></tr>
    <tr><td class="paramdir">[in]</td><td class="paramname">bias_data</td><td>Vector of bias data, added to each sum. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The function returns <code>RISCV_NMSIS_NN_SUCCESS</code> - Successful operation </dd></dl>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated on Wed May 14 2025 04:08:31 for NMSIS-NN by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
