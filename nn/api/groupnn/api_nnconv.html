

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Convolution Functions &mdash; NMSIS 1.0.2-RC2 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Fully-connected Layer Functions" href="api_fc.html" />
    <link rel="prev" title="Concatenation Functions" href="api_concatenation.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html">
          

          
            
            <img src="../../../_static/nmsis_logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                1.0.2-RC2
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../../../introduction/introduction.html">Nuclei MCU Software Interface Standard(NMSIS)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../core/index.html">NMSIS Core</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../dsp/index.html">NMSIS DSP</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../../index.html">NMSIS NN</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="../../overview.html">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../get_started.html">Using NMSIS-NN</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="../index.html">NMSIS NN API</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="../api_groupnn.html">Neural Network Functions</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="api_acti.html">Activation Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_basicmath.html">Basic math functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_concatenation.html">Concatenation Functions</a></li>
<li class="toctree-l4 current"><a class="current reference internal" href="#">Convolution Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_fc.html">Fully-connected Layer Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_pooling.html">Pooling Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_reshape.html">Reshape Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_softmax.html">Softmax Functions</a></li>
<li class="toctree-l4"><a class="reference internal" href="api_svdf.html">SVDF Layer Functions</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../api_nndata_convert.html">Neural Network Data Conversion Functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_nnbasicmath.html">Basic Math Functions for Neural Network Computation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_cnnexample.html">Convolutional Neural Network Example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../api_gruexample.html">Gated Recurrent Unit Example</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../changelog.html">Changelog</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../changelog.html">Changelog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../glossary.html">Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../appendix.html">Appendix</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">NMSIS</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html">Docs</a> &raquo;</li>
        
          <li><a href="../../index.html">NMSIS NN</a> &raquo;</li>
        
          <li><a href="../index.html">NMSIS NN API</a> &raquo;</li>
        
          <li><a href="../api_groupnn.html">Neural Network Functions</a> &raquo;</li>
        
      <li>Convolution Functions</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../../_sources/nn/api/groupnn/api_nnconv.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="convolution-functions">
<span id="nmsis-nn-api-convolution-functions"></span><h1>Convolution Functions<a class="headerlink" href="#convolution-functions" title="Permalink to this headline">¶</a></h1>
<dl class="function">
<dt id="_CPPv423riscv_convolve_1_x_n_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv323riscv_convolve_1_x_n_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv223riscv_convolve_1_x_n_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="riscv_convolve_1_x_n_s8__nmsis_nn_contextCP.nmsis_nn_conv_paramsCP.nmsis_nn_per_channel_quant_paramsCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.int32_tCP.nmsis_nn_dimsCP.q7_tP"></span><span class="target" id="group__NNConv_1gabaa21da3ad72b8c790efd27917a58982"></span>riscv_status <code class="sig-name descname">riscv_convolve_1_x_n_s8</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_conv_params *<em>conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv423riscv_convolve_1_x_n_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv439riscv_convolve_1_x_n_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims">
<span id="_CPPv339riscv_convolve_1_x_n_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="_CPPv239riscv_convolve_1_x_n_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="riscv_convolve_1_x_n_s8_get_buffer_size__nmsis_nn_dimsCP.nmsis_nn_dimsCP"></span><span class="target" id="group__NNConv_1gad5d4e038de80a33c437fe39f48c523f4"></span>int32_t <code class="sig-name descname">riscv_convolve_1_x_n_s8_get_buffer_size</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv439riscv_convolve_1_x_n_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv440riscv_convolve_1x1_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv340riscv_convolve_1x1_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv240riscv_convolve_1x1_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="riscv_convolve_1x1_HWC_q7_fast_nonsquare__q7_tCP.uint16_tC.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.q7_tP.uint16_tC.uint16_tC.q15_tP.q7_tP"></span><span class="target" id="group__NNConv_1ga6c935af4ca6a80b7b747ff90e1e5c91a"></span>riscv_status <code class="sig-name descname">riscv_convolve_1x1_HWC_q7_fast_nonsquare</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in_x</em>, <em class="property">const</em> uint16_t <em>dim_im_in_y</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel_x</em>, <em class="property">const</em> uint16_t <em>dim_kernel_y</em>, <em class="property">const</em> uint16_t <em>padding_x</em>, <em class="property">const</em> uint16_t <em>padding_y</em>, <em class="property">const</em> uint16_t <em>stride_x</em>, <em class="property">const</em> uint16_t <em>stride_y</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out_x</em>, <em class="property">const</em> uint16_t <em>dim_im_out_y</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv440riscv_convolve_1x1_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv426riscv_convolve_1x1_s8_fastPK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv326riscv_convolve_1x1_s8_fastPK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv226riscv_convolve_1x1_s8_fastPK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="riscv_convolve_1x1_s8_fast__nmsis_nn_contextCP.nmsis_nn_conv_paramsCP.nmsis_nn_per_channel_quant_paramsCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.int32_tCP.nmsis_nn_dimsCP.q7_tP"></span><span class="target" id="group__NNConv_1gaa04044f1e2cb1ae5c3c0d7abe473e187"></span>riscv_status <code class="sig-name descname">riscv_convolve_1x1_s8_fast</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_conv_params *<em>conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv426riscv_convolve_1x1_s8_fastPK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv442riscv_convolve_1x1_s8_fast_get_buffer_sizePK13nmsis_nn_dims">
<span id="_CPPv342riscv_convolve_1x1_s8_fast_get_buffer_sizePK13nmsis_nn_dims"></span><span id="_CPPv242riscv_convolve_1x1_s8_fast_get_buffer_sizePK13nmsis_nn_dims"></span><span id="riscv_convolve_1x1_s8_fast_get_buffer_size__nmsis_nn_dimsCP"></span><span class="target" id="group__NNConv_1ga194f5ffb4b714e99b263280283702b1a"></span>int32_t <code class="sig-name descname">riscv_convolve_1x1_s8_fast_get_buffer_size</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_dims *<em>input_dims</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv442riscv_convolve_1x1_s8_fast_get_buffer_sizePK13nmsis_nn_dims" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv428riscv_convolve_HWC_q15_basicPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv328riscv_convolve_HWC_q15_basicPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv228riscv_convolve_HWC_q15_basicPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t"></span><span id="riscv_convolve_HWC_q15_basic__q15_tCP.uint16_tC.uint16_tC.q15_tCP.uint16_tC.uint16_tC.uint16_tC.uint16_tC.q15_tCP.uint16_tC.uint16_tC.q15_tP.uint16_tC.q15_tP.q7_tP"></span><span class="target" id="group__NNConv_1ga24b8f2757e31020336b4e4d663f9f116"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q15_basic</code><span class="sig-paren">(</span><em class="property">const</em> q15_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q15_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel</em>, <em class="property">const</em> uint16_t <em>padding</em>, <em class="property">const</em> uint16_t <em>stride</em>, <em class="property">const</em> q15_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q15_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv428riscv_convolve_HWC_q15_basicPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv427riscv_convolve_HWC_q15_fastPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv327riscv_convolve_HWC_q15_fastPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv227riscv_convolve_HWC_q15_fastPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t"></span><span id="riscv_convolve_HWC_q15_fast__q15_tCP.uint16_tC.uint16_tC.q15_tCP.uint16_tC.uint16_tC.uint16_tC.uint16_tC.q15_tCP.uint16_tC.uint16_tC.q15_tP.uint16_tC.q15_tP.q7_tP"></span><span class="target" id="group__NNConv_1ga9685fbf9f838fcc9306b3962bb6d04df"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q15_fast</code><span class="sig-paren">(</span><em class="property">const</em> q15_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q15_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel</em>, <em class="property">const</em> uint16_t <em>padding</em>, <em class="property">const</em> uint16_t <em>stride</em>, <em class="property">const</em> q15_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q15_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv427riscv_convolve_HWC_q15_fastPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv437riscv_convolve_HWC_q15_fast_nonsquarePK5q15_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv337riscv_convolve_HWC_q15_fast_nonsquarePK5q15_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv237riscv_convolve_HWC_q15_fast_nonsquarePK5q15_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="riscv_convolve_HWC_q15_fast_nonsquare__q15_tCP.uint16_tC.uint16_tC.uint16_tC.q15_tCP.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.q15_tCP.uint16_tC.uint16_tC.q15_tP.uint16_tC.uint16_tC.q15_tP.q7_tP"></span><span class="target" id="group__NNConv_1ga205837a93b5bd574a95c97b7d843551c"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q15_fast_nonsquare</code><span class="sig-paren">(</span><em class="property">const</em> q15_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in_x</em>, <em class="property">const</em> uint16_t <em>dim_im_in_y</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q15_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel_x</em>, <em class="property">const</em> uint16_t <em>dim_kernel_y</em>, <em class="property">const</em> uint16_t <em>padding_x</em>, <em class="property">const</em> uint16_t <em>padding_y</em>, <em class="property">const</em> uint16_t <em>stride_x</em>, <em class="property">const</em> uint16_t <em>stride_y</em>, <em class="property">const</em> q15_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q15_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out_x</em>, <em class="property">const</em> uint16_t <em>dim_im_out_y</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv437riscv_convolve_HWC_q15_fast_nonsquarePK5q15_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tK8uint16_tP5q15_tP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv427riscv_convolve_HWC_q7_basicPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv327riscv_convolve_HWC_q7_basicPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv227riscv_convolve_HWC_q7_basicPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span id="riscv_convolve_HWC_q7_basic__q7_tCP.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.q7_tP.uint16_tC.q15_tP.q7_tP"></span><span class="target" id="group__NNConv_1ga053353a7bdfca7d1aa9461210048d74a"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q7_basic</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel</em>, <em class="property">const</em> uint16_t <em>padding</em>, <em class="property">const</em> uint16_t <em>stride</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv427riscv_convolve_HWC_q7_basicPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv437riscv_convolve_HWC_q7_basic_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv337riscv_convolve_HWC_q7_basic_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv237riscv_convolve_HWC_q7_basic_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="riscv_convolve_HWC_q7_basic_nonsquare__q7_tCP.uint16_tC.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.q7_tP.uint16_tC.uint16_tC.q15_tP.q7_tP"></span><span class="target" id="group__NNConv_1ga2434b44e25c1c62c6c9da25382bd3e08"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q7_basic_nonsquare</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in_x</em>, <em class="property">const</em> uint16_t <em>dim_im_in_y</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel_x</em>, <em class="property">const</em> uint16_t <em>dim_kernel_y</em>, <em class="property">const</em> uint16_t <em>padding_x</em>, <em class="property">const</em> uint16_t <em>padding_y</em>, <em class="property">const</em> uint16_t <em>stride_x</em>, <em class="property">const</em> uint16_t <em>stride_y</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out_x</em>, <em class="property">const</em> uint16_t <em>dim_im_out_y</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv437riscv_convolve_HWC_q7_basic_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv426riscv_convolve_HWC_q7_fastPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv326riscv_convolve_HWC_q7_fastPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv226riscv_convolve_HWC_q7_fastPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span id="riscv_convolve_HWC_q7_fast__q7_tCP.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.q7_tP.uint16_tC.q15_tP.q7_tP"></span><span class="target" id="group__NNConv_1gaad778ec0d290ffa07f58c5b32cb8a80b"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q7_fast</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel</em>, <em class="property">const</em> uint16_t <em>padding</em>, <em class="property">const</em> uint16_t <em>stride</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv426riscv_convolve_HWC_q7_fastPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv436riscv_convolve_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv336riscv_convolve_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv236riscv_convolve_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="riscv_convolve_HWC_q7_fast_nonsquare__q7_tCP.uint16_tC.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.q7_tP.uint16_tC.uint16_tC.q15_tP.q7_tP"></span><span class="target" id="group__NNConv_1gaea6b13bcf602586c83033ce6310b1ca5"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q7_fast_nonsquare</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in_x</em>, <em class="property">const</em> uint16_t <em>dim_im_in_y</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel_x</em>, <em class="property">const</em> uint16_t <em>dim_kernel_y</em>, <em class="property">const</em> uint16_t <em>padding_x</em>, <em class="property">const</em> uint16_t <em>padding_y</em>, <em class="property">const</em> uint16_t <em>stride_x</em>, <em class="property">const</em> uint16_t <em>stride_y</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out_x</em>, <em class="property">const</em> uint16_t <em>dim_im_out_y</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv436riscv_convolve_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv425riscv_convolve_HWC_q7_RGBPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv325riscv_convolve_HWC_q7_RGBPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv225riscv_convolve_HWC_q7_RGBPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span id="riscv_convolve_HWC_q7_RGB__q7_tCP.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.q7_tP.uint16_tC.q15_tP.q7_tP"></span><span class="target" id="group__NNConv_1ga0a64a6e39851c858266bcb1227a431d4"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q7_RGB</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel</em>, <em class="property">const</em> uint16_t <em>padding</em>, <em class="property">const</em> uint16_t <em>stride</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv425riscv_convolve_HWC_q7_RGBPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv417riscv_convolve_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv317riscv_convolve_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv217riscv_convolve_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="riscv_convolve_s8__nmsis_nn_contextCP.nmsis_nn_conv_paramsCP.nmsis_nn_per_channel_quant_paramsCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.int32_tCP.nmsis_nn_dimsCP.q7_tP"></span><span class="target" id="group__NNConv_1ga723ae9312a46cbc7687931df988ff772"></span>riscv_status <code class="sig-name descname">riscv_convolve_s8</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_conv_params *<em>conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv417riscv_convolve_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv433riscv_convolve_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims">
<span id="_CPPv333riscv_convolve_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="_CPPv233riscv_convolve_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="riscv_convolve_s8_get_buffer_size__nmsis_nn_dimsCP.nmsis_nn_dimsCP"></span><span class="target" id="group__NNConv_1ga268e623b07753f8f29cf72f9ec1ff249"></span>int32_t <code class="sig-name descname">riscv_convolve_s8_get_buffer_size</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv433riscv_convolve_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv425riscv_convolve_wrapper_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv325riscv_convolve_wrapper_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv225riscv_convolve_wrapper_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="riscv_convolve_wrapper_s8__nmsis_nn_contextCP.nmsis_nn_conv_paramsCP.nmsis_nn_per_channel_quant_paramsCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.int32_tCP.nmsis_nn_dimsCP.q7_tP"></span><span class="target" id="group__NNConv_1ga47d4a71f628d2b45d982b7f090011ca8"></span>riscv_status <code class="sig-name descname">riscv_convolve_wrapper_s8</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_conv_params *<em>conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv425riscv_convolve_wrapper_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv441riscv_convolve_wrapper_s8_get_buffer_sizePK20nmsis_nn_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims">
<span id="_CPPv341riscv_convolve_wrapper_s8_get_buffer_sizePK20nmsis_nn_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="_CPPv241riscv_convolve_wrapper_s8_get_buffer_sizePK20nmsis_nn_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="riscv_convolve_wrapper_s8_get_buffer_size__nmsis_nn_conv_paramsCP.nmsis_nn_dimsCP.nmsis_nn_dimsCP.nmsis_nn_dimsCP"></span><span class="target" id="group__NNConv_1gad619a8fad8f7995394b9e6b1be9896e4"></span>int32_t <code class="sig-name descname">riscv_convolve_wrapper_s8_get_buffer_size</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_conv_params *<em>conv_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv441riscv_convolve_wrapper_s8_get_buffer_sizePK20nmsis_nn_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv427riscv_depthwise_conv_3x3_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv327riscv_depthwise_conv_3x3_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv227riscv_depthwise_conv_3x3_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="riscv_depthwise_conv_3x3_s8__nmsis_nn_contextCP.nmsis_nn_dw_conv_paramsCP.nmsis_nn_per_channel_quant_paramsCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.int32_tCP.nmsis_nn_dimsCP.q7_tP"></span><span class="target" id="group__NNConv_1gad8c0e2e6040122db541485e69e8e256e"></span>riscv_status <code class="sig-name descname">riscv_depthwise_conv_3x3_s8</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_dw_conv_params *<em>dw_conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv427riscv_depthwise_conv_3x3_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv424depthwise_conv_s8_mult_4PK6int8_tK7int32_tK7int32_tK7int32_tPK6int8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP6int8_tPK7int32_tPK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t">
<span id="_CPPv324depthwise_conv_s8_mult_4PK6int8_tK7int32_tK7int32_tK7int32_tPK6int8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP6int8_tPK7int32_tPK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="_CPPv224depthwise_conv_s8_mult_4PK6int8_tK7int32_tK7int32_tK7int32_tPK6int8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP6int8_tPK7int32_tPK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="depthwise_conv_s8_mult_4__int8_tCP.int32_tC.int32_tC.int32_tC.int8_tCP.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tCP.int8_tP.int32_tCP.int32_tCP.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC"></span><span class="target" id="group__NNConv_1ga06d7783f6788faad5165fd0ae583bc59"></span><em class="property">static</em> void <code class="sig-name descname">depthwise_conv_s8_mult_4</code><span class="sig-paren">(</span><em class="property">const</em> int8_t *<em>input</em>, <em class="property">const</em> int32_t <em>input_x</em>, <em class="property">const</em> int32_t <em>input_y</em>, <em class="property">const</em> int32_t <em>input_ch</em>, <em class="property">const</em> int8_t *<em>kernel</em>, <em class="property">const</em> int32_t <em>output_ch</em>, <em class="property">const</em> int32_t <em>ch_mult</em>, <em class="property">const</em> int32_t <em>kernel_x</em>, <em class="property">const</em> int32_t <em>kernel_y</em>, <em class="property">const</em> int32_t <em>pad_x</em>, <em class="property">const</em> int32_t <em>pad_y</em>, <em class="property">const</em> int32_t <em>stride_x</em>, <em class="property">const</em> int32_t <em>stride_y</em>, <em class="property">const</em> int32_t *<em>bias</em>, int8_t *<em>output</em>, <em class="property">const</em> int32_t *<em>output_shift</em>, <em class="property">const</em> int32_t *<em>output_mult</em>, <em class="property">const</em> int32_t <em>output_x</em>, <em class="property">const</em> int32_t <em>output_y</em>, <em class="property">const</em> int32_t <em>output_offset</em>, <em class="property">const</em> int32_t <em>input_offset</em>, <em class="property">const</em> int32_t <em>output_activation_min</em>, <em class="property">const</em> int32_t <em>output_activation_max</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv424depthwise_conv_s8_mult_4PK6int8_tK7int32_tK7int32_tK7int32_tPK6int8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP6int8_tPK7int32_tPK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv425depthwise_conv_s8_genericPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK7int32_tP4q7_tPK7int32_tPK7int32_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t">
<span id="_CPPv325depthwise_conv_s8_genericPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK7int32_tP4q7_tPK7int32_tPK7int32_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="_CPPv225depthwise_conv_s8_genericPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK7int32_tP4q7_tPK7int32_tPK7int32_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="depthwise_conv_s8_generic__q7_tCP.uint16_tC.uint16_tC.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.int32_tCP.q7_tP.int32_tCP.int32_tCP.uint16_tC.uint16_tC.int32_tC.int32_tC.int32_tC.int32_tC"></span><span class="target" id="group__NNConv_1gae9f070a198f67a5337700b0a6cf7ef21"></span><em class="property">static</em> void <code class="sig-name descname">depthwise_conv_s8_generic</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>input</em>, <em class="property">const</em> uint16_t <em>input_batches</em>, <em class="property">const</em> uint16_t <em>input_x</em>, <em class="property">const</em> uint16_t <em>input_y</em>, <em class="property">const</em> uint16_t <em>input_ch</em>, <em class="property">const</em> q7_t *<em>kernel</em>, <em class="property">const</em> uint16_t <em>output_ch</em>, <em class="property">const</em> uint16_t <em>ch_mult</em>, <em class="property">const</em> uint16_t <em>kernel_x</em>, <em class="property">const</em> uint16_t <em>kernel_y</em>, <em class="property">const</em> uint16_t <em>pad_x</em>, <em class="property">const</em> uint16_t <em>pad_y</em>, <em class="property">const</em> uint16_t <em>stride_x</em>, <em class="property">const</em> uint16_t <em>stride_y</em>, <em class="property">const</em> int32_t *<em>bias</em>, q7_t *<em>output</em>, <em class="property">const</em> int32_t *<em>output_shift</em>, <em class="property">const</em> int32_t *<em>output_mult</em>, <em class="property">const</em> uint16_t <em>output_x</em>, <em class="property">const</em> uint16_t <em>output_y</em>, <em class="property">const</em> int32_t <em>output_offset</em>, <em class="property">const</em> int32_t <em>input_offset</em>, <em class="property">const</em> int32_t <em>output_activation_min</em>, <em class="property">const</em> int32_t <em>output_activation_max</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv425depthwise_conv_s8_genericPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK7int32_tP4q7_tPK7int32_tPK7int32_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv423riscv_depthwise_conv_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv323riscv_depthwise_conv_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv223riscv_depthwise_conv_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="riscv_depthwise_conv_s8__nmsis_nn_contextCP.nmsis_nn_dw_conv_paramsCP.nmsis_nn_per_channel_quant_paramsCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.int32_tCP.nmsis_nn_dimsCP.q7_tP"></span><span class="target" id="group__NNConv_1gaa5c81bf587c87928ba1990cc0aa51368"></span>riscv_status <code class="sig-name descname">riscv_depthwise_conv_s8</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_dw_conv_params *<em>dw_conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv423riscv_depthwise_conv_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv427riscv_depthwise_conv_s8_optPK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv327riscv_depthwise_conv_s8_optPK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv227riscv_depthwise_conv_s8_optPK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="riscv_depthwise_conv_s8_opt__nmsis_nn_contextCP.nmsis_nn_dw_conv_paramsCP.nmsis_nn_per_channel_quant_paramsCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.int32_tCP.nmsis_nn_dimsCP.q7_tP"></span><span class="target" id="group__NNConv_1ga163c256dbe831cac3cb2c8069e7e110c"></span>riscv_status <code class="sig-name descname">riscv_depthwise_conv_s8_opt</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_dw_conv_params *<em>dw_conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv427riscv_depthwise_conv_s8_optPK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv443riscv_depthwise_conv_s8_opt_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims">
<span id="_CPPv343riscv_depthwise_conv_s8_opt_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="_CPPv243riscv_depthwise_conv_s8_opt_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="riscv_depthwise_conv_s8_opt_get_buffer_size__nmsis_nn_dimsCP.nmsis_nn_dimsCP"></span><span class="target" id="group__NNConv_1gaf0c3458a5d997da11bacd258c7a86ab7"></span>int32_t <code class="sig-name descname">riscv_depthwise_conv_s8_opt_get_buffer_size</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv443riscv_depthwise_conv_s8_opt_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv424depthwise_conv_u8_mult_4PK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t">
<span id="_CPPv324depthwise_conv_u8_mult_4PK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="_CPPv224depthwise_conv_u8_mult_4PK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="depthwise_conv_u8_mult_4__uint8_tCP.int32_tC.int32_tC.int32_tC.uint8_tCP.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tCP.uint8_tP.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC"></span><span class="target" id="group__NNConv_1ga4c54b5bdb38fc20c2167bdfa289f1a2b"></span><em class="property">static</em> void <code class="sig-name descname">depthwise_conv_u8_mult_4</code><span class="sig-paren">(</span><em class="property">const</em> uint8_t *<em>input</em>, <em class="property">const</em> int32_t <em>input_x</em>, <em class="property">const</em> int32_t <em>input_y</em>, <em class="property">const</em> int32_t <em>input_ch</em>, <em class="property">const</em> uint8_t *<em>kernel</em>, <em class="property">const</em> int32_t <em>output_ch</em>, <em class="property">const</em> int32_t <em>ch_mult</em>, <em class="property">const</em> int32_t <em>kernel_x</em>, <em class="property">const</em> int32_t <em>kernel_y</em>, <em class="property">const</em> int32_t <em>pad_x</em>, <em class="property">const</em> int32_t <em>pad_y</em>, <em class="property">const</em> int32_t <em>stride_x</em>, <em class="property">const</em> int32_t <em>stride_y</em>, <em class="property">const</em> int32_t *<em>bias</em>, uint8_t *<em>output</em>, <em class="property">const</em> int32_t <em>output_shift</em>, <em class="property">const</em> int32_t <em>output_mult</em>, <em class="property">const</em> int32_t <em>output_x</em>, <em class="property">const</em> int32_t <em>output_y</em>, <em class="property">const</em> int32_t <em>output_offset</em>, <em class="property">const</em> int32_t <em>input_offset</em>, <em class="property">const</em> int32_t <em>filter_offset</em>, <em class="property">const</em> int32_t <em>output_activation_min</em>, <em class="property">const</em> int32_t <em>output_activation_max</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv424depthwise_conv_u8_mult_4PK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv425depthwise_conv_u8_genericPK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t">
<span id="_CPPv325depthwise_conv_u8_genericPK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="_CPPv225depthwise_conv_u8_genericPK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="depthwise_conv_u8_generic__uint8_tCP.int32_tC.int32_tC.int32_tC.uint8_tCP.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tCP.uint8_tP.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC.int32_tC"></span><span class="target" id="group__NNConv_1gab98fd934700dff7667131744c8972d91"></span><em class="property">static</em> void <code class="sig-name descname">depthwise_conv_u8_generic</code><span class="sig-paren">(</span><em class="property">const</em> uint8_t *<em>input</em>, <em class="property">const</em> int32_t <em>input_x</em>, <em class="property">const</em> int32_t <em>input_y</em>, <em class="property">const</em> int32_t <em>input_ch</em>, <em class="property">const</em> uint8_t *<em>kernel</em>, <em class="property">const</em> int32_t <em>output_ch</em>, <em class="property">const</em> int32_t <em>ch_mult</em>, <em class="property">const</em> int32_t <em>kernel_x</em>, <em class="property">const</em> int32_t <em>kernel_y</em>, <em class="property">const</em> int32_t <em>pad_x</em>, <em class="property">const</em> int32_t <em>pad_y</em>, <em class="property">const</em> int32_t <em>stride_x</em>, <em class="property">const</em> int32_t <em>stride_y</em>, <em class="property">const</em> int32_t *<em>bias</em>, uint8_t *<em>output</em>, <em class="property">const</em> int32_t <em>output_shift</em>, <em class="property">const</em> int32_t <em>output_mult</em>, <em class="property">const</em> int32_t <em>output_x</em>, <em class="property">const</em> int32_t <em>output_y</em>, <em class="property">const</em> int32_t <em>output_offset</em>, <em class="property">const</em> int32_t <em>input_offset</em>, <em class="property">const</em> int32_t <em>filter_offset</em>, <em class="property">const</em> int32_t <em>output_activation_min</em>, <em class="property">const</em> int32_t <em>output_activation_max</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv425depthwise_conv_u8_genericPK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv434riscv_depthwise_conv_u8_basic_ver1PK7uint8_tK8uint16_tK8uint16_tK8uint16_tPK7uint8_tK8uint16_tK8uint16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tPK7int32_tK7int32_tK7int32_tK7int32_tP7uint8_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t">
<span id="_CPPv334riscv_depthwise_conv_u8_basic_ver1PK7uint8_tK8uint16_tK8uint16_tK8uint16_tPK7uint8_tK8uint16_tK8uint16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tPK7int32_tK7int32_tK7int32_tK7int32_tP7uint8_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="_CPPv234riscv_depthwise_conv_u8_basic_ver1PK7uint8_tK8uint16_tK8uint16_tK8uint16_tPK7uint8_tK8uint16_tK8uint16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tPK7int32_tK7int32_tK7int32_tK7int32_tP7uint8_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="riscv_depthwise_conv_u8_basic_ver1__uint8_tCP.uint16_tC.uint16_tC.uint16_tC.uint8_tCP.uint16_tC.uint16_tC.int16_tC.int16_tC.int16_tC.int16_tC.int16_tC.int16_tC.int16_tC.int32_tCP.int32_tC.int32_tC.int32_tC.uint8_tP.uint16_tC.uint16_tC.int32_tC.int32_tC.int32_tC.int32_tC"></span><span class="target" id="group__NNConv_1gaa3a3e0fac3bbb5d7b5ac90a21ee4ade8"></span>riscv_status <code class="sig-name descname">riscv_depthwise_conv_u8_basic_ver1</code><span class="sig-paren">(</span><em class="property">const</em> uint8_t *<em>input</em>, <em class="property">const</em> uint16_t <em>input_x</em>, <em class="property">const</em> uint16_t <em>input_y</em>, <em class="property">const</em> uint16_t <em>input_ch</em>, <em class="property">const</em> uint8_t *<em>kernel</em>, <em class="property">const</em> uint16_t <em>kernel_x</em>, <em class="property">const</em> uint16_t <em>kernel_y</em>, <em class="property">const</em> int16_t <em>ch_mult</em>, <em class="property">const</em> int16_t <em>pad_x</em>, <em class="property">const</em> int16_t <em>pad_y</em>, <em class="property">const</em> int16_t <em>stride_x</em>, <em class="property">const</em> int16_t <em>stride_y</em>, <em class="property">const</em> int16_t <em>dilation_x</em>, <em class="property">const</em> int16_t <em>dilation_y</em>, <em class="property">const</em> int32_t *<em>bias</em>, <em class="property">const</em> int32_t <em>input_offset</em>, <em class="property">const</em> int32_t <em>filter_offset</em>, <em class="property">const</em> int32_t <em>output_offset</em>, uint8_t *<em>output</em>, <em class="property">const</em> uint16_t <em>output_x</em>, <em class="property">const</em> uint16_t <em>output_y</em>, <em class="property">const</em> int32_t <em>output_activation_min</em>, <em class="property">const</em> int32_t <em>output_activation_max</em>, <em class="property">const</em> int32_t <em>output_shift</em>, <em class="property">const</em> int32_t <em>output_mult</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv434riscv_depthwise_conv_u8_basic_ver1PK7uint8_tK8uint16_tK8uint16_tK8uint16_tPK7uint8_tK8uint16_tK8uint16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tPK7int32_tK7int32_tK7int32_tK7int32_tP7uint8_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv431riscv_depthwise_conv_wrapper_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv331riscv_depthwise_conv_wrapper_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv231riscv_depthwise_conv_wrapper_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="riscv_depthwise_conv_wrapper_s8__nmsis_nn_contextCP.nmsis_nn_dw_conv_paramsCP.nmsis_nn_per_channel_quant_paramsCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.q7_tCP.nmsis_nn_dimsCP.int32_tCP.nmsis_nn_dimsCP.q7_tP"></span><span class="target" id="group__NNConv_1gadd730f9b8a5497148c7441b28461c0c6"></span>riscv_status <code class="sig-name descname">riscv_depthwise_conv_wrapper_s8</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_dw_conv_params *<em>dw_conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv431riscv_depthwise_conv_wrapper_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv447riscv_depthwise_conv_wrapper_s8_get_buffer_sizePK23nmsis_nn_dw_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims">
<span id="_CPPv347riscv_depthwise_conv_wrapper_s8_get_buffer_sizePK23nmsis_nn_dw_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="_CPPv247riscv_depthwise_conv_wrapper_s8_get_buffer_sizePK23nmsis_nn_dw_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="riscv_depthwise_conv_wrapper_s8_get_buffer_size__nmsis_nn_dw_conv_paramsCP.nmsis_nn_dimsCP.nmsis_nn_dimsCP.nmsis_nn_dimsCP"></span><span class="target" id="group__NNConv_1ga6ef29f06fe7ad6af657dadc07f49ba2c"></span>int32_t <code class="sig-name descname">riscv_depthwise_conv_wrapper_s8_get_buffer_size</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_dw_conv_params *<em>dw_conv_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv447riscv_depthwise_conv_wrapper_s8_get_buffer_sizePK23nmsis_nn_dw_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv437riscv_depthwise_separable_conv_HWC_q7PK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv337riscv_depthwise_separable_conv_HWC_q7PK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv237riscv_depthwise_separable_conv_HWC_q7PK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span id="riscv_depthwise_separable_conv_HWC_q7__q7_tCP.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.q7_tP.uint16_tC.q15_tP.q7_tP"></span><span class="target" id="group__NNConv_1ga73a880af4ffcae5ba0229a20890b05d4"></span>riscv_status <code class="sig-name descname">riscv_depthwise_separable_conv_HWC_q7</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel</em>, <em class="property">const</em> uint16_t <em>padding</em>, <em class="property">const</em> uint16_t <em>stride</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv437riscv_depthwise_separable_conv_HWC_q7PK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv447riscv_depthwise_separable_conv_HWC_q7_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv347riscv_depthwise_separable_conv_HWC_q7_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv247riscv_depthwise_separable_conv_HWC_q7_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="riscv_depthwise_separable_conv_HWC_q7_nonsquare__q7_tCP.uint16_tC.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.uint16_tC.q7_tCP.uint16_tC.uint16_tC.q7_tP.uint16_tC.uint16_tC.q15_tP.q7_tP"></span><span class="target" id="group__NNConv_1gaec2d2b8c1536a08db1811d8971f20f66"></span>riscv_status <code class="sig-name descname">riscv_depthwise_separable_conv_HWC_q7_nonsquare</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in_x</em>, <em class="property">const</em> uint16_t <em>dim_im_in_y</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel_x</em>, <em class="property">const</em> uint16_t <em>dim_kernel_y</em>, <em class="property">const</em> uint16_t <em>padding_x</em>, <em class="property">const</em> uint16_t <em>padding_y</em>, <em class="property">const</em> uint16_t <em>stride_x</em>, <em class="property">const</em> uint16_t <em>stride_y</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out_x</em>, <em class="property">const</em> uint16_t <em>dim_im_out_y</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><a class="headerlink" href="#_CPPv447riscv_depthwise_separable_conv_HWC_q7_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t" title="Permalink to this definition">¶</a><br /></dt>
<dd></dd></dl>

<dl class="group">
<dt>
<span class="target" id="group__NNConv"></span><em>group</em> <code class="sig-name descname">NNConv</code></dt>
<dd><p>Collection of convolution, depthwise convolution functions and their variants.</p>
<p>The convolution is implemented in 2 steps: im2col and GEMM</p>
<p>im2col is a process of converting each patch of image data into a column. After im2col, the convolution is computed as matrix-matrix multiplication.</p>
<p>To reduce the memory footprint, the im2col is performed partially. Each iteration, only a few column (i.e., patches) are generated and computed with GEMM kernels similar to NMSIS-DSP riscv_mat_mult functions. </p>
<div class="breathe-sectiondef docutils container">
<p class="breathe-sectiondef-title rubric">Functions</p>
<dl class="function">
<dt id="_CPPv423riscv_convolve_1_x_n_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv323riscv_convolve_1_x_n_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv223riscv_convolve_1_x_n_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span class="target" id="group__NNConv_1gabaa21da3ad72b8c790efd27917a58982"></span>riscv_status <code class="sig-name descname">riscv_convolve_1_x_n_s8</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_conv_params *<em>conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><br /></dt>
<dd><p>1xn convolution </p>
<p><ul class="simple">
<li><p>Supported framework : TensorFlow Lite Micro</p></li>
<li><p>The following constrains on the arguments apply<ol class="arabic simple">
<li><p>input_dims-&gt;n equals 1</p></li>
<li><p>ouput_dims-&gt;w is a multiple of 4</p></li>
<li><p>Explicit constraints(since it is for 1xN convolution) -## input_dims-&gt;h equals 1 -## output_dims-&gt;h equals 1 -## filter_dims-&gt;h equals 1 </p></li>
</ol>
</p></li>
</ul>
<dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns either <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> if argument constraints fail. or, <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> on successful completion.</p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">ctx</span></code>: Function context that contains the additional buffer if required by the function. riscv_convolve_1_x_n_s8_get_buffer_size will return the buffer_size if required </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">conv_params</span></code>: Convolution parameters (e.g. strides, dilations, pads,…). Range of conv_params-&gt;input_offset : [-127, 128] Range of conv_params-&gt;output_offset : [-128, 127] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">quant_params</span></code>: Per-channel quantization info. It contains the multiplier and shift values to be applied to each output channel </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_dims</span></code>: Input (activation) tensor dimensions. Format: [N, H, W, C_IN] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_data</span></code>: Input (activation) data pointer. Data type: int8 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_dims</span></code>: Filter tensor dimensions. Format: [C_OUT, 1, WK, C_IN] where WK is the horizontal spatial filter dimension </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_data</span></code>: Filter data pointer. Data type: int8 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_dims</span></code>: Bias tensor dimensions. Format: [C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_data</span></code>: Optional bias data pointer. Data type: int32 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_dims</span></code>: Output tensor dimensions. Format: [N, H, W, C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[out]</span> <span class="pre">output_data</span></code>: Output data pointer. Data type: int8</p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv439riscv_convolve_1_x_n_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims">
<span id="_CPPv339riscv_convolve_1_x_n_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="_CPPv239riscv_convolve_1_x_n_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span class="target" id="group__NNConv_1gad5d4e038de80a33c437fe39f48c523f4"></span>int32_t <code class="sig-name descname">riscv_convolve_1_x_n_s8_get_buffer_size</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Get the required additional buffer size for 1xn convolution. </p>
<p><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns required buffer size(bytes) </p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_dims</span></code>: Input (activation) tensor dimensions. Format: [N, H, W, C_IN] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_dims</span></code>: Filter tensor dimensions. Format: [C_OUT, 1, WK, C_IN] where WK is the horizontal spatial filter dimension </p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv440riscv_convolve_1x1_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv340riscv_convolve_1x1_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv240riscv_convolve_1x1_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span class="target" id="group__NNConv_1ga6c935af4ca6a80b7b747ff90e1e5c91a"></span>riscv_status <code class="sig-name descname">riscv_convolve_1x1_HWC_q7_fast_nonsquare</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in_x</em>, <em class="property">const</em> uint16_t <em>dim_im_in_y</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel_x</em>, <em class="property">const</em> uint16_t <em>dim_kernel_y</em>, <em class="property">const</em> uint16_t <em>padding_x</em>, <em class="property">const</em> uint16_t <em>padding_y</em>, <em class="property">const</em> uint16_t <em>stride_x</em>, <em class="property">const</em> uint16_t <em>stride_y</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out_x</em>, <em class="property">const</em> uint16_t <em>dim_im_out_y</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Fast Q7 version of 1x1 convolution (non-sqaure shape) </p>
<p><p>This function is optimized for convolution with 1x1 kernel size (i.e., dim_kernel_x=1 and dim_kernel_y=1). It can be used for the second half of MobileNets [1] after depthwise separable convolution.</p>
<dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns either <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> or <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> based on the outcome of size checking.</p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">Im_in</span></code>: pointer to input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in_x</span></code>: input tensor dimention x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in_y</span></code>: input tensor dimention y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_in</span></code>: number of input tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">wt</span></code>: pointer to kernel weights </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_out</span></code>: number of filters, i.e., output tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel_x</span></code>: filter kernel size x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel_y</span></code>: filter kernel size y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding_x</span></code>: padding size x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding_y</span></code>: padding size y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride_x</span></code>: convolution stride x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride_y</span></code>: convolution stride y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias</span></code>: pointer to bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_shift</span></code>: amount of left-shift for bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">out_shift</span></code>: amount of right-shift for output </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">Im_out</span></code>: pointer to output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out_x</span></code>: output tensor dimension x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out_y</span></code>: output tensor dimension y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferA</span></code>: pointer to buffer space for input </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferB</span></code>: pointer to buffer space for output </p></li>
</ul>
</dd>
</dl>
</p>
<p>This function is the version with full list of optimization tricks, but with some constraints: ch_im_in is multiple of 4 ch_im_out is multiple of 2</p>
<p>[1] MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications <a class="reference external" href="https://arxiv.org/abs/1704.04861">https://arxiv.org/abs/1704.04861</a> </p>
</dd></dl>

<dl class="function">
<dt id="_CPPv426riscv_convolve_1x1_s8_fastPK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv326riscv_convolve_1x1_s8_fastPK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv226riscv_convolve_1x1_s8_fastPK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span class="target" id="group__NNConv_1gaa04044f1e2cb1ae5c3c0d7abe473e187"></span>riscv_status <code class="sig-name descname">riscv_convolve_1x1_s8_fast</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_conv_params *<em>conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Fast s8 version for 1x1 convolution (non-square shape) </p>
<p><ul class="simple">
<li><p>Supported framework : TensorFlow Lite Micro</p></li>
<li><p>The following constrains on the arguments apply<ol class="arabic simple">
<li><p>input_dims-&gt;c is a multiple of 4</p></li>
<li><p>conv_params-&gt;padding.w = conv_params-&gt;padding.h = 0</p></li>
<li><p>conv_params-&gt;stride.w = conv_params-&gt;stride.h = 1 </p></li>
</ol>
</p></li>
</ul>
<dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns either <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> if argument constraints fail. or, <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> on successful completion.</p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">ctx</span></code>: Function context that contains the additional buffer if required by the function. riscv_convolve_1x1_s8_fast_get_buffer_size will return the buffer_size if required </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">conv_params</span></code>: Convolution parameters (e.g. strides, dilations, pads,…). Range of conv_params-&gt;input_offset : [-127, 128] Range of conv_params-&gt;output_offset : [-128, 127] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">quant_params</span></code>: Per-channel quantization info. It contains the multiplier and shift values to be applied to each output channel </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_dims</span></code>: Input (activation) tensor dimensions. Format: [N, H, W, C_IN] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_data</span></code>: Input (activation) data pointer. Data type: int8 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_dims</span></code>: Filter tensor dimensions. Format: [C_OUT, 1, 1, C_IN] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_data</span></code>: Filter data pointer. Data type: int8 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_dims</span></code>: Bias tensor dimensions. Format: [C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_data</span></code>: Optional bias data pointer. Data type: int32 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_dims</span></code>: Output tensor dimensions. Format: [N, H, W, C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[out]</span> <span class="pre">output_data</span></code>: Output data pointer. Data type: int8</p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv442riscv_convolve_1x1_s8_fast_get_buffer_sizePK13nmsis_nn_dims">
<span id="_CPPv342riscv_convolve_1x1_s8_fast_get_buffer_sizePK13nmsis_nn_dims"></span><span id="_CPPv242riscv_convolve_1x1_s8_fast_get_buffer_sizePK13nmsis_nn_dims"></span><span class="target" id="group__NNConv_1ga194f5ffb4b714e99b263280283702b1a"></span>int32_t <code class="sig-name descname">riscv_convolve_1x1_s8_fast_get_buffer_size</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_dims *<em>input_dims</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Get the required buffer size for riscv_convolve_1x1_s8_fast. </p>
<p><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns the required buffer size in bytes </p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_dims</span></code>: Input (activation) dimensions </p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv428riscv_convolve_HWC_q15_basicPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv328riscv_convolve_HWC_q15_basicPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv228riscv_convolve_HWC_q15_basicPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t"></span><span class="target" id="group__NNConv_1ga24b8f2757e31020336b4e4d663f9f116"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q15_basic</code><span class="sig-paren">(</span><em class="property">const</em> q15_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q15_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel</em>, <em class="property">const</em> uint16_t <em>padding</em>, <em class="property">const</em> uint16_t <em>stride</em>, <em class="property">const</em> q15_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q15_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Basic Q15 convolution function. </p>
<p><strong>Buffer size:</strong><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code></p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">Im_in</span></code>: pointer to input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in</span></code>: input tensor dimention </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_in</span></code>: number of input tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">wt</span></code>: pointer to kernel weights </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_out</span></code>: number of filters, i.e., output tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel</span></code>: filter kernel size </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding</span></code>: padding sizes </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride</span></code>: convolution stride </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias</span></code>: pointer to bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_shift</span></code>: amount of left-shift for bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">out_shift</span></code>: amount of right-shift for output </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">Im_out</span></code>: pointer to output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out</span></code>: output tensor dimension </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferA</span></code>: pointer to buffer space for input </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferB</span></code>: pointer to buffer space for output </p></li>
</ul>
</dd>
</dl>
</p>
<p>bufferA size: ch_im_in*dim_kernel*dim_kernel</p>
<p>bufferB size: 0</p>
<p>This basic version is designed to work for any input tensor and weight dimension. </p>
</dd></dl>

<dl class="function">
<dt id="_CPPv427riscv_convolve_HWC_q15_fastPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv327riscv_convolve_HWC_q15_fastPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv227riscv_convolve_HWC_q15_fastPK5q15_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tP5q15_tP4q7_t"></span><span class="target" id="group__NNConv_1ga9685fbf9f838fcc9306b3962bb6d04df"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q15_fast</code><span class="sig-paren">(</span><em class="property">const</em> q15_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q15_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel</em>, <em class="property">const</em> uint16_t <em>padding</em>, <em class="property">const</em> uint16_t <em>stride</em>, <em class="property">const</em> q15_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q15_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Fast Q15 convolution function. </p>
<p><strong>Buffer size:</strong><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns either <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> or <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> based on the outcome of size checking.</p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">Im_in</span></code>: pointer to input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in</span></code>: input tensor dimention </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_in</span></code>: number of input tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">wt</span></code>: pointer to kernel weights </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_out</span></code>: number of filters, i.e., output tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel</span></code>: filter kernel size </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding</span></code>: padding sizes </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride</span></code>: convolution stride </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias</span></code>: pointer to bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_shift</span></code>: amount of left-shift for bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">out_shift</span></code>: amount of right-shift for output </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">Im_out</span></code>: pointer to output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out</span></code>: output tensor dimension </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferA</span></code>: pointer to buffer space for input </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferB</span></code>: pointer to buffer space for output </p></li>
</ul>
</dd>
</dl>
</p>
<p>bufferA size: 2*ch_im_in*dim_kernel*dim_kernel</p>
<p>bufferB size: 0</p>
<p><strong>Input dimension constraints:</strong></p>
<p>ch_im_in is multiple of 2</p>
<p>ch_im_out is multiple of 2 </p>
</dd></dl>

<dl class="function">
<dt id="_CPPv437riscv_convolve_HWC_q15_fast_nonsquarePK5q15_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv337riscv_convolve_HWC_q15_fast_nonsquarePK5q15_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv237riscv_convolve_HWC_q15_fast_nonsquarePK5q15_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK5q15_tK8uint16_tK8uint16_tP5q15_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span class="target" id="group__NNConv_1ga205837a93b5bd574a95c97b7d843551c"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q15_fast_nonsquare</code><span class="sig-paren">(</span><em class="property">const</em> q15_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in_x</em>, <em class="property">const</em> uint16_t <em>dim_im_in_y</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q15_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel_x</em>, <em class="property">const</em> uint16_t <em>dim_kernel_y</em>, <em class="property">const</em> uint16_t <em>padding_x</em>, <em class="property">const</em> uint16_t <em>padding_y</em>, <em class="property">const</em> uint16_t <em>stride_x</em>, <em class="property">const</em> uint16_t <em>stride_y</em>, <em class="property">const</em> q15_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q15_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out_x</em>, <em class="property">const</em> uint16_t <em>dim_im_out_y</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Fast Q15 convolution function (non-sqaure shape) </p>
<p><strong>Buffer size:</strong><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns either <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> or <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> based on the outcome of size checking.</p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">Im_in</span></code>: pointer to input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in_x</span></code>: input tensor dimention x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in_y</span></code>: input tensor dimention y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_in</span></code>: number of input tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">wt</span></code>: pointer to kernel weights </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_out</span></code>: number of filters, i.e., output tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel_x</span></code>: filter kernel size x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel_y</span></code>: filter kernel size y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding_x</span></code>: padding size x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding_y</span></code>: padding size y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride_x</span></code>: convolution stride x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride_y</span></code>: convolution stride y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias</span></code>: pointer to bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_shift</span></code>: amount of left-shift for bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">out_shift</span></code>: amount of right-shift for output </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">Im_out</span></code>: pointer to output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out_x</span></code>: output tensor dimension x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out_y</span></code>: output tensor dimension y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferA</span></code>: pointer to buffer space for input </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferB</span></code>: pointer to buffer space for output </p></li>
</ul>
</dd>
</dl>
</p>
<p>bufferA size: 2*ch_im_in*dim_kernel*dim_kernel</p>
<p>bufferB size: 0</p>
<p><strong>Input dimension constraints:</strong></p>
<p>ch_im_in is multiple of 2</p>
<p>ch_im_out is multiple of 2 </p>
</dd></dl>

<dl class="function">
<dt id="_CPPv427riscv_convolve_HWC_q7_basicPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv327riscv_convolve_HWC_q7_basicPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv227riscv_convolve_HWC_q7_basicPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span class="target" id="group__NNConv_1ga053353a7bdfca7d1aa9461210048d74a"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q7_basic</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel</em>, <em class="property">const</em> uint16_t <em>padding</em>, <em class="property">const</em> uint16_t <em>stride</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Basic Q7 convolution function. </p>
<p><strong>Buffer size:</strong><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code></p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">Im_in</span></code>: pointer to input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in</span></code>: input tensor dimention </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_in</span></code>: number of input tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">wt</span></code>: pointer to kernel weights </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_out</span></code>: number of filters, i.e., output tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel</span></code>: filter kernel size </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding</span></code>: padding sizes </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride</span></code>: convolution stride </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias</span></code>: pointer to bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_shift</span></code>: amount of left-shift for bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">out_shift</span></code>: amount of right-shift for output </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">Im_out</span></code>: pointer to output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out</span></code>: output tensor dimension </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferA</span></code>: pointer to buffer space for input </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferB</span></code>: pointer to buffer space for output </p></li>
</ul>
</dd>
</dl>
</p>
<p>bufferA size: 2*ch_im_in*dim_kernel*dim_kernel</p>
<p>bufferB size: 0</p>
<p>This basic version is designed to work for any input tensor and weight dimension. </p>
</dd></dl>

<dl class="function">
<dt id="_CPPv437riscv_convolve_HWC_q7_basic_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv337riscv_convolve_HWC_q7_basic_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv237riscv_convolve_HWC_q7_basic_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span class="target" id="group__NNConv_1ga2434b44e25c1c62c6c9da25382bd3e08"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q7_basic_nonsquare</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in_x</em>, <em class="property">const</em> uint16_t <em>dim_im_in_y</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel_x</em>, <em class="property">const</em> uint16_t <em>dim_kernel_y</em>, <em class="property">const</em> uint16_t <em>padding_x</em>, <em class="property">const</em> uint16_t <em>padding_y</em>, <em class="property">const</em> uint16_t <em>stride_x</em>, <em class="property">const</em> uint16_t <em>stride_y</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out_x</em>, <em class="property">const</em> uint16_t <em>dim_im_out_y</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Basic Q7 convolution function (non-sqaure shape) </p>
<p>Basic Q7 convolution function (non-square shape)</p>
<p><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> </p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">Im_in</span></code>: pointer to input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in_x</span></code>: input tensor dimention x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in_y</span></code>: input tensor dimention y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_in</span></code>: number of input tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">wt</span></code>: pointer to kernel weights </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_out</span></code>: number of filters, i.e., output tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel_x</span></code>: filter kernel size x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel_y</span></code>: filter kernel size y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding_x</span></code>: padding size x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding_y</span></code>: padding size y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride_x</span></code>: convolution stride x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride_y</span></code>: convolution stride y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias</span></code>: pointer to bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_shift</span></code>: amount of left-shift for bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">out_shift</span></code>: amount of right-shift for output </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">Im_out</span></code>: pointer to output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out_x</span></code>: output tensor dimension x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out_y</span></code>: output tensor dimension y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferA</span></code>: pointer to buffer space for input </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferB</span></code>: pointer to buffer space for output </p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv426riscv_convolve_HWC_q7_fastPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv326riscv_convolve_HWC_q7_fastPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv226riscv_convolve_HWC_q7_fastPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span class="target" id="group__NNConv_1gaad778ec0d290ffa07f58c5b32cb8a80b"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q7_fast</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel</em>, <em class="property">const</em> uint16_t <em>padding</em>, <em class="property">const</em> uint16_t <em>stride</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Fast Q7 convolution function. </p>
<p><strong>Buffer size:</strong><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns either <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> or <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> based on the outcome of size checking.</p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">Im_in</span></code>: pointer to input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in</span></code>: input tensor dimention </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_in</span></code>: number of input tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">wt</span></code>: pointer to kernel weights </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_out</span></code>: number of filters, i.e., output tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel</span></code>: filter kernel size </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding</span></code>: padding sizes </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride</span></code>: convolution stride </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias</span></code>: pointer to bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_shift</span></code>: amount of left-shift for bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">out_shift</span></code>: amount of right-shift for output </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">Im_out</span></code>: pointer to output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out</span></code>: output tensor dimension </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferA</span></code>: pointer to buffer space for input </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferB</span></code>: pointer to buffer space for output </p></li>
</ul>
</dd>
</dl>
</p>
<p>bufferA size: 2*ch_im_in*dim_kernel*dim_kernel</p>
<p>bufferB size: 0</p>
<p><strong>Input dimension constraints:</strong></p>
<p>ch_im_in is multiple of 4 ( because of the SIMD32 read and swap )</p>
<p>ch_im_out is multiple of 2 ( bacause 2x2 mat_mult kernel )</p>
<p>The im2col converts the Q7 tensor input into Q15 column, which is stored in bufferA. There is reordering happenning during this im2col process with riscv_q7_to_q15_reordered_no_shift. For every four elements, the second and third elements are swapped.</p>
<p>The computation kernel riscv_nn_mat_mult_kernel_q7_q15_reordered does the GEMM computation with the reordered columns.</p>
<p>To speed-up the determination of the padding condition, we split the computation into 3x3 parts, i.e., {top, mid, bottom} X {left, mid, right}. This reduces the total number of boundary condition checks and improves the data copying performance. </p>
</dd></dl>

<dl class="function">
<dt id="_CPPv436riscv_convolve_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv336riscv_convolve_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv236riscv_convolve_HWC_q7_fast_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span class="target" id="group__NNConv_1gaea6b13bcf602586c83033ce6310b1ca5"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q7_fast_nonsquare</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in_x</em>, <em class="property">const</em> uint16_t <em>dim_im_in_y</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel_x</em>, <em class="property">const</em> uint16_t <em>dim_kernel_y</em>, <em class="property">const</em> uint16_t <em>padding_x</em>, <em class="property">const</em> uint16_t <em>padding_y</em>, <em class="property">const</em> uint16_t <em>stride_x</em>, <em class="property">const</em> uint16_t <em>stride_y</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out_x</em>, <em class="property">const</em> uint16_t <em>dim_im_out_y</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Fast Q7 convolution function (non-sqaure shape) </p>
<p><p>This function is the version with full list of optimization tricks, but with some constraints: ch_im_in is multiple of 4 ch_im_out is multiple of 2 </p>
<dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns either <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> or <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> based on the outcome of size checking.</p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">Im_in</span></code>: pointer to input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in_x</span></code>: input tensor dimention x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in_y</span></code>: input tensor dimention y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_in</span></code>: number of input tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">wt</span></code>: pointer to kernel weights </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_out</span></code>: number of filters, i.e., output tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel_x</span></code>: filter kernel size x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel_y</span></code>: filter kernel size y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding_x</span></code>: padding size x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding_y</span></code>: padding size y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride_x</span></code>: convolution stride x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride_y</span></code>: convolution stride y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias</span></code>: pointer to bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_shift</span></code>: amount of left-shift for bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">out_shift</span></code>: amount of right-shift for output </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">Im_out</span></code>: pointer to output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out_x</span></code>: output tensor dimension x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out_y</span></code>: output tensor dimension y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferA</span></code>: pointer to buffer space for input </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferB</span></code>: pointer to buffer space for output </p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv425riscv_convolve_HWC_q7_RGBPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv325riscv_convolve_HWC_q7_RGBPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv225riscv_convolve_HWC_q7_RGBPK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span class="target" id="group__NNConv_1ga0a64a6e39851c858266bcb1227a431d4"></span>riscv_status <code class="sig-name descname">riscv_convolve_HWC_q7_RGB</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel</em>, <em class="property">const</em> uint16_t <em>padding</em>, <em class="property">const</em> uint16_t <em>stride</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Q7 convolution function for RGB image. </p>
<p>Q7 version of convolution for RGB image.</p>
<p><strong>Buffer size:</strong><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns either <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> or <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> based on the outcome of size checking.</p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">Im_in</span></code>: pointer to input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in</span></code>: input tensor dimention </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_in</span></code>: number of input tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">wt</span></code>: pointer to kernel weights </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_out</span></code>: number of filters, i.e., output tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel</span></code>: filter kernel size </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding</span></code>: padding sizes </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride</span></code>: convolution stride </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias</span></code>: pointer to bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_shift</span></code>: amount of left-shift for bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">out_shift</span></code>: amount of right-shift for output </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">Im_out</span></code>: pointer to output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out</span></code>: output tensor dimension </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferA</span></code>: pointer to buffer space for input </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferB</span></code>: pointer to buffer space for output </p></li>
</ul>
</dd>
</dl>
</p>
<p>bufferA size: 2*ch_im_in*dim_kernel*dim_kernel</p>
<p>bufferB size: 0</p>
<p><strong>Input dimension constraints:</strong></p>
<p>ch_im_in equals 3</p>
<p>This kernel is written exclusively for convolution with ch_im_in equals 3. This applies on the first layer of CNNs which has input image with RGB format. </p>
</dd></dl>

<dl class="function">
<dt id="_CPPv417riscv_convolve_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv317riscv_convolve_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv217riscv_convolve_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span class="target" id="group__NNConv_1ga723ae9312a46cbc7687931df988ff772"></span>riscv_status <code class="sig-name descname">riscv_convolve_s8</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_conv_params *<em>conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Basic s8 convolution function. </p>
<p><ol class="arabic simple">
<li><p>Supported framework: TensorFlow Lite micro</p></li>
<li><p>q7 is used as data type eventhough it is s8 data. It is done so to be consistent with existing APIs.</p></li>
<li><p>Additional memory is required for optimization. Refer to argument ‘ctx’ for details. </p></li>
</ol>
<dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code></p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">ctx</span></code>: Function context that contains the additional buffer if required by the function. riscv_convolve_s8_get_buffer_size will return the buffer_size if required </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">conv_params</span></code>: Convolution parameters (e.g. strides, dilations, pads,…). Range of conv_params-&gt;input_offset : [-127, 128] Range of conv_params-&gt;output_offset : [-128, 127] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">quant_params</span></code>: Per-channel quantization info. It contains the multiplier and shift values to be applied to each output channel </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_dims</span></code>: Input (activation) tensor dimensions. Format: [N, H, W, C_IN] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_data</span></code>: Input (activation) data pointer. Data type: int8 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_dims</span></code>: Filter tensor dimensions. Format: [C_OUT, HK, WK, C_IN] where HK and WK are the spatial filter dimensions </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_data</span></code>: Filter data pointer. Data type: int8 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_dims</span></code>: Bias tensor dimensions. Format: [C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_data</span></code>: Optional bias data pointer. Data type: int32 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_dims</span></code>: Output tensor dimensions. Format: [N, H, W, C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[out]</span> <span class="pre">output_data</span></code>: Output data pointer. Data type: int8</p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv433riscv_convolve_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims">
<span id="_CPPv333riscv_convolve_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="_CPPv233riscv_convolve_s8_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span class="target" id="group__NNConv_1ga268e623b07753f8f29cf72f9ec1ff249"></span>int32_t <code class="sig-name descname">riscv_convolve_s8_get_buffer_size</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Get the required buffer size for s8 convolution function. </p>
<p><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns required buffer size(bytes) </p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_dims</span></code>: Input (activation) tensor dimensions. Format: [N, H, W, C_IN] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_dims</span></code>: Filter tensor dimensions. Format: [C_OUT, HK, WK, C_IN] where HK and WK are the spatial filter dimensions </p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv425riscv_convolve_wrapper_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv325riscv_convolve_wrapper_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv225riscv_convolve_wrapper_s8PK16nmsis_nn_contextPK20nmsis_nn_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span class="target" id="group__NNConv_1ga47d4a71f628d2b45d982b7f090011ca8"></span>riscv_status <code class="sig-name descname">riscv_convolve_wrapper_s8</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_conv_params *<em>conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><br /></dt>
<dd><p>s8 convolution layer wrapper function with the main purpose to call the optimal kernel available in nmsis-nn to perform the convolution. </p>
<p><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns either <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> if argument constraints fail. or, <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> on successful completion. </p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">ctx</span></code>: Function context that contains the additional buffer if required by the function. riscv_convolve_wrapper_s8_get_buffer_size will return the buffer_size if required </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">conv_params</span></code>: Convolution parameters (e.g. strides, dilations, pads,…). Range of conv_params-&gt;input_offset : [-127, 128] Range of conv_params-&gt;output_offset : [-128, 127] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">quant_params</span></code>: Per-channel quantization info. It contains the multiplier and shift values to be applied to each output channel </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_dims</span></code>: Input (activation) tensor dimensions. Format: [N, H, W, C_IN] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_data</span></code>: Input (activation) data pointer. Data type: int8 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_dims</span></code>: Filter tensor dimensions. Format: [C_OUT, HK, WK, C_IN] where HK and WK are the spatial filter dimensions </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_data</span></code>: Filter data pointer. Data type: int8 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_dims</span></code>: Bias tensor dimensions. Format: [C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_data</span></code>: Bias data pointer. Data type: int32 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_dims</span></code>: Output tensor dimensions. Format: [N, H, W, C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[out]</span> <span class="pre">output_data</span></code>: Output data pointer. Data type: int8</p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv441riscv_convolve_wrapper_s8_get_buffer_sizePK20nmsis_nn_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims">
<span id="_CPPv341riscv_convolve_wrapper_s8_get_buffer_sizePK20nmsis_nn_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="_CPPv241riscv_convolve_wrapper_s8_get_buffer_sizePK20nmsis_nn_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span class="target" id="group__NNConv_1gad619a8fad8f7995394b9e6b1be9896e4"></span>int32_t <code class="sig-name descname">riscv_convolve_wrapper_s8_get_buffer_size</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_conv_params *<em>conv_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Get the required buffer size for riscv_convolve_wrapper_s8. </p>
<p><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns required buffer size(bytes) </p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">conv_params</span></code>: Convolution parameters (e.g. strides, dilations, pads,…). Range of conv_params-&gt;input_offset : [-127, 128] Range of conv_params-&gt;output_offset : [-128, 127] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_dims</span></code>: Input (activation) dimensions. Format: [N, H, W, C_IN] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_dims</span></code>: Filter dimensions. Format: [C_OUT, HK, WK, C_IN] where HK and WK are the spatial filter dimensions </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_dims</span></code>: Output tensor dimensions. Format: [N, H, W, C_OUT]</p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv427riscv_depthwise_conv_3x3_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv327riscv_depthwise_conv_3x3_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv227riscv_depthwise_conv_3x3_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span class="target" id="group__NNConv_1gad8c0e2e6040122db541485e69e8e256e"></span>riscv_status <code class="sig-name descname">riscv_depthwise_conv_3x3_s8</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_dw_conv_params *<em>dw_conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Optimized s8 depthwise convolution function for 3x3 kernel size with some constraints on the input arguments(documented below). Refer riscv_depthwise_conv_s8() for function argument details. </p>
<p><ul class="simple">
<li><p>Supported framework : TensorFlow Lite Micro</p></li>
<li><p>The following constrains on the arguments apply<ol class="arabic simple">
<li><p>Number of input channel equals number of output channels</p></li>
<li><p>Filter height and width equals 3</p></li>
<li><p>Padding along x is either 0 or 1. </p></li>
</ol>
</p></li>
</ul>
<dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns one of the following <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> - Unsupported dimension of tensors <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_ARGUMENT_ERROR</span></code> - Unsupported pad size along the x axis <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> - Successful operation</p>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv424depthwise_conv_s8_mult_4PK6int8_tK7int32_tK7int32_tK7int32_tPK6int8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP6int8_tPK7int32_tPK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t">
<span id="_CPPv324depthwise_conv_s8_mult_4PK6int8_tK7int32_tK7int32_tK7int32_tPK6int8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP6int8_tPK7int32_tPK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="_CPPv224depthwise_conv_s8_mult_4PK6int8_tK7int32_tK7int32_tK7int32_tPK6int8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP6int8_tPK7int32_tPK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span class="target" id="group__NNConv_1ga06d7783f6788faad5165fd0ae583bc59"></span><em class="property">static</em> void <code class="sig-name descname">depthwise_conv_s8_mult_4</code><span class="sig-paren">(</span><em class="property">const</em> int8_t *<em>input</em>, <em class="property">const</em> int32_t <em>input_x</em>, <em class="property">const</em> int32_t <em>input_y</em>, <em class="property">const</em> int32_t <em>input_ch</em>, <em class="property">const</em> int8_t *<em>kernel</em>, <em class="property">const</em> int32_t <em>output_ch</em>, <em class="property">const</em> int32_t <em>ch_mult</em>, <em class="property">const</em> int32_t <em>kernel_x</em>, <em class="property">const</em> int32_t <em>kernel_y</em>, <em class="property">const</em> int32_t <em>pad_x</em>, <em class="property">const</em> int32_t <em>pad_y</em>, <em class="property">const</em> int32_t <em>stride_x</em>, <em class="property">const</em> int32_t <em>stride_y</em>, <em class="property">const</em> int32_t *<em>bias</em>, int8_t *<em>output</em>, <em class="property">const</em> int32_t *<em>output_shift</em>, <em class="property">const</em> int32_t *<em>output_mult</em>, <em class="property">const</em> int32_t <em>output_x</em>, <em class="property">const</em> int32_t <em>output_y</em>, <em class="property">const</em> int32_t <em>output_offset</em>, <em class="property">const</em> int32_t <em>input_offset</em>, <em class="property">const</em> int32_t <em>output_activation_min</em>, <em class="property">const</em> int32_t <em>output_activation_max</em><span class="sig-paren">)</span><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv425depthwise_conv_s8_genericPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK7int32_tP4q7_tPK7int32_tPK7int32_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t">
<span id="_CPPv325depthwise_conv_s8_genericPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK7int32_tP4q7_tPK7int32_tPK7int32_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="_CPPv225depthwise_conv_s8_genericPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK7int32_tP4q7_tPK7int32_tPK7int32_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span class="target" id="group__NNConv_1gae9f070a198f67a5337700b0a6cf7ef21"></span><em class="property">static</em> void <code class="sig-name descname">depthwise_conv_s8_generic</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>input</em>, <em class="property">const</em> uint16_t <em>input_batches</em>, <em class="property">const</em> uint16_t <em>input_x</em>, <em class="property">const</em> uint16_t <em>input_y</em>, <em class="property">const</em> uint16_t <em>input_ch</em>, <em class="property">const</em> q7_t *<em>kernel</em>, <em class="property">const</em> uint16_t <em>output_ch</em>, <em class="property">const</em> uint16_t <em>ch_mult</em>, <em class="property">const</em> uint16_t <em>kernel_x</em>, <em class="property">const</em> uint16_t <em>kernel_y</em>, <em class="property">const</em> uint16_t <em>pad_x</em>, <em class="property">const</em> uint16_t <em>pad_y</em>, <em class="property">const</em> uint16_t <em>stride_x</em>, <em class="property">const</em> uint16_t <em>stride_y</em>, <em class="property">const</em> int32_t *<em>bias</em>, q7_t *<em>output</em>, <em class="property">const</em> int32_t *<em>output_shift</em>, <em class="property">const</em> int32_t *<em>output_mult</em>, <em class="property">const</em> uint16_t <em>output_x</em>, <em class="property">const</em> uint16_t <em>output_y</em>, <em class="property">const</em> int32_t <em>output_offset</em>, <em class="property">const</em> int32_t <em>input_offset</em>, <em class="property">const</em> int32_t <em>output_activation_min</em>, <em class="property">const</em> int32_t <em>output_activation_max</em><span class="sig-paren">)</span><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv423riscv_depthwise_conv_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv323riscv_depthwise_conv_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv223riscv_depthwise_conv_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span class="target" id="group__NNConv_1gaa5c81bf587c87928ba1990cc0aa51368"></span>riscv_status <code class="sig-name descname">riscv_depthwise_conv_s8</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_dw_conv_params *<em>dw_conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Basic s8 depthwise convolution function that doesn’t have any constraints on the input dimensions. </p>
<p><ul class="simple">
<li><p>Supported framework: TensorFlow Lite</p></li>
<li><p>q7 is used as data type eventhough it is s8 data. It is done so to be consistent with existing APIs. </p></li>
</ul>
<dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code></p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">ctx</span></code>: Function context (e.g. temporary buffer). Check the function definition file to see if an additional buffer is required. Optional function {API}_get_buffer_size() provides the buffer size if an additional buffer is required. exists if additional memory is. </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dw_conv_params</span></code>: Depthwise convolution parameters (e.g. strides, dilations, pads,…) dw_conv_params-&gt;dilation is not used. Range of dw_conv_params-&gt;input_offset : [-127, 128] Range of dw_conv_params-&gt;input_offset : [-128, 127] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">quant_params</span></code>: Per-channel quantization info. It contains the multiplier and shift values to be applied to each output channel </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_dims</span></code>: Input (activation) tensor dimensions. Format: [1, H, W, C_IN] Batch argument N is not used. </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_data</span></code>: Input (activation) data pointer. Data type: int8 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_dims</span></code>: Filter tensor dimensions. Format: [1, H, W, C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_data</span></code>: Filter data pointer. Data type: int8 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_dims</span></code>: Bias tensor dimensions. Format: [C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_data</span></code>: Bias data pointer. Data type: int32 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_dims</span></code>: Output tensor dimensions. Format: [1, H, W, C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">output_data</span></code>: Output data pointer. Data type: int8 </p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv427riscv_depthwise_conv_s8_optPK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv327riscv_depthwise_conv_s8_optPK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv227riscv_depthwise_conv_s8_optPK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span class="target" id="group__NNConv_1ga163c256dbe831cac3cb2c8069e7e110c"></span>riscv_status <code class="sig-name descname">riscv_depthwise_conv_s8_opt</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_dw_conv_params *<em>dw_conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Optimized s8 depthwise convolution function with constraint that in_channel equals out_channel. Refer riscv_depthwise_conv_s8() for function argument details. </p>
<p><ul class="simple">
<li><p>Supported framework: TensorFlow Lite</p></li>
<li><p>The following constrains on the arguments apply<ol class="arabic simple">
<li><p>Number of input channel equals number of output channels or ch_mult equals 1</p></li>
</ol>
</p></li>
<li><p>q7 is used as data type eventhough it is s8 data. It is done so to be consistent with existing APIs.</p></li>
<li><p>Reccomended when number of channels is 4 or greater. </p></li>
</ul>
<dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns one of the following <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> - input channel != output channel or ch_mult != 1 <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> - Successful operation</p>
</dd>
<dt><strong>Note</strong></dt><dd><p>If number of channels is not a multiple of 4, upto 3 elements outside the boundary will be read out for the following if MVE optimizations(Arm Helium Technology) are used.<ul class="simple">
<li><p>Output shift</p></li>
<li><p>Output multiplier</p></li>
<li><p>Output bias</p></li>
<li><p>kernel</p></li>
</ul>
</p>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv443riscv_depthwise_conv_s8_opt_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims">
<span id="_CPPv343riscv_depthwise_conv_s8_opt_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="_CPPv243riscv_depthwise_conv_s8_opt_get_buffer_sizePK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span class="target" id="group__NNConv_1gaf0c3458a5d997da11bacd258c7a86ab7"></span>int32_t <code class="sig-name descname">riscv_depthwise_conv_s8_opt_get_buffer_size</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Get the required buffer size for optimized s8 depthwise convolution function with constraint that in_channel equals out_channel. </p>
<p><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns required buffer size in bytes </p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_dims</span></code>: Input (activation) tensor dimensions. Format: [1, H, W, C_IN] Batch argument N is not used. </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_dims</span></code>: Filter tensor dimensions. Format: [1, H, W, C_OUT] </p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv424depthwise_conv_u8_mult_4PK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t">
<span id="_CPPv324depthwise_conv_u8_mult_4PK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="_CPPv224depthwise_conv_u8_mult_4PK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span class="target" id="group__NNConv_1ga4c54b5bdb38fc20c2167bdfa289f1a2b"></span><em class="property">static</em> void <code class="sig-name descname">depthwise_conv_u8_mult_4</code><span class="sig-paren">(</span><em class="property">const</em> uint8_t *<em>input</em>, <em class="property">const</em> int32_t <em>input_x</em>, <em class="property">const</em> int32_t <em>input_y</em>, <em class="property">const</em> int32_t <em>input_ch</em>, <em class="property">const</em> uint8_t *<em>kernel</em>, <em class="property">const</em> int32_t <em>output_ch</em>, <em class="property">const</em> int32_t <em>ch_mult</em>, <em class="property">const</em> int32_t <em>kernel_x</em>, <em class="property">const</em> int32_t <em>kernel_y</em>, <em class="property">const</em> int32_t <em>pad_x</em>, <em class="property">const</em> int32_t <em>pad_y</em>, <em class="property">const</em> int32_t <em>stride_x</em>, <em class="property">const</em> int32_t <em>stride_y</em>, <em class="property">const</em> int32_t *<em>bias</em>, uint8_t *<em>output</em>, <em class="property">const</em> int32_t <em>output_shift</em>, <em class="property">const</em> int32_t <em>output_mult</em>, <em class="property">const</em> int32_t <em>output_x</em>, <em class="property">const</em> int32_t <em>output_y</em>, <em class="property">const</em> int32_t <em>output_offset</em>, <em class="property">const</em> int32_t <em>input_offset</em>, <em class="property">const</em> int32_t <em>filter_offset</em>, <em class="property">const</em> int32_t <em>output_activation_min</em>, <em class="property">const</em> int32_t <em>output_activation_max</em><span class="sig-paren">)</span><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv425depthwise_conv_u8_genericPK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t">
<span id="_CPPv325depthwise_conv_u8_genericPK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="_CPPv225depthwise_conv_u8_genericPK7uint8_tK7int32_tK7int32_tK7int32_tPK7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tPK7int32_tP7uint8_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span class="target" id="group__NNConv_1gab98fd934700dff7667131744c8972d91"></span><em class="property">static</em> void <code class="sig-name descname">depthwise_conv_u8_generic</code><span class="sig-paren">(</span><em class="property">const</em> uint8_t *<em>input</em>, <em class="property">const</em> int32_t <em>input_x</em>, <em class="property">const</em> int32_t <em>input_y</em>, <em class="property">const</em> int32_t <em>input_ch</em>, <em class="property">const</em> uint8_t *<em>kernel</em>, <em class="property">const</em> int32_t <em>output_ch</em>, <em class="property">const</em> int32_t <em>ch_mult</em>, <em class="property">const</em> int32_t <em>kernel_x</em>, <em class="property">const</em> int32_t <em>kernel_y</em>, <em class="property">const</em> int32_t <em>pad_x</em>, <em class="property">const</em> int32_t <em>pad_y</em>, <em class="property">const</em> int32_t <em>stride_x</em>, <em class="property">const</em> int32_t <em>stride_y</em>, <em class="property">const</em> int32_t *<em>bias</em>, uint8_t *<em>output</em>, <em class="property">const</em> int32_t <em>output_shift</em>, <em class="property">const</em> int32_t <em>output_mult</em>, <em class="property">const</em> int32_t <em>output_x</em>, <em class="property">const</em> int32_t <em>output_y</em>, <em class="property">const</em> int32_t <em>output_offset</em>, <em class="property">const</em> int32_t <em>input_offset</em>, <em class="property">const</em> int32_t <em>filter_offset</em>, <em class="property">const</em> int32_t <em>output_activation_min</em>, <em class="property">const</em> int32_t <em>output_activation_max</em><span class="sig-paren">)</span><br /></dt>
<dd></dd></dl>

<dl class="function">
<dt id="_CPPv434riscv_depthwise_conv_u8_basic_ver1PK7uint8_tK8uint16_tK8uint16_tK8uint16_tPK7uint8_tK8uint16_tK8uint16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tPK7int32_tK7int32_tK7int32_tK7int32_tP7uint8_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t">
<span id="_CPPv334riscv_depthwise_conv_u8_basic_ver1PK7uint8_tK8uint16_tK8uint16_tK8uint16_tPK7uint8_tK8uint16_tK8uint16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tPK7int32_tK7int32_tK7int32_tK7int32_tP7uint8_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span id="_CPPv234riscv_depthwise_conv_u8_basic_ver1PK7uint8_tK8uint16_tK8uint16_tK8uint16_tPK7uint8_tK8uint16_tK8uint16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tK7int16_tPK7int32_tK7int32_tK7int32_tK7int32_tP7uint8_tK8uint16_tK8uint16_tK7int32_tK7int32_tK7int32_tK7int32_t"></span><span class="target" id="group__NNConv_1gaa3a3e0fac3bbb5d7b5ac90a21ee4ade8"></span>riscv_status <code class="sig-name descname">riscv_depthwise_conv_u8_basic_ver1</code><span class="sig-paren">(</span><em class="property">const</em> uint8_t *<em>input</em>, <em class="property">const</em> uint16_t <em>input_x</em>, <em class="property">const</em> uint16_t <em>input_y</em>, <em class="property">const</em> uint16_t <em>input_ch</em>, <em class="property">const</em> uint8_t *<em>kernel</em>, <em class="property">const</em> uint16_t <em>kernel_x</em>, <em class="property">const</em> uint16_t <em>kernel_y</em>, <em class="property">const</em> int16_t <em>ch_mult</em>, <em class="property">const</em> int16_t <em>pad_x</em>, <em class="property">const</em> int16_t <em>pad_y</em>, <em class="property">const</em> int16_t <em>stride_x</em>, <em class="property">const</em> int16_t <em>stride_y</em>, <em class="property">const</em> int16_t <em>dilation_x</em>, <em class="property">const</em> int16_t <em>dilation_y</em>, <em class="property">const</em> int32_t *<em>bias</em>, <em class="property">const</em> int32_t <em>input_offset</em>, <em class="property">const</em> int32_t <em>filter_offset</em>, <em class="property">const</em> int32_t <em>output_offset</em>, uint8_t *<em>output</em>, <em class="property">const</em> uint16_t <em>output_x</em>, <em class="property">const</em> uint16_t <em>output_y</em>, <em class="property">const</em> int32_t <em>output_activation_min</em>, <em class="property">const</em> int32_t <em>output_activation_max</em>, <em class="property">const</em> int32_t <em>output_shift</em>, <em class="property">const</em> int32_t <em>output_mult</em><span class="sig-paren">)</span><br /></dt>
<dd><p>uint8 depthwise convolution function with asymmetric quantization </p>
<p>uint8 depthwise convolution function with asymmetric quantization Unless specified otherwise, arguments are mandatory.</p>
<p><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns one of the following <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> - Not supported dimension of tensors <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> - Successful operation <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_ARGUMENT_ERROR</span></code> - Implementation not available </p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input</span></code>: Pointer to input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_x</span></code>: Width of input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_y</span></code>: Height of input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_ch</span></code>: Channels in input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">kernel</span></code>: Pointer to kernel weights </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">kernel_x</span></code>: Width of kernel </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">kernel_y</span></code>: Height of kernel </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_mult</span></code>: Number of channel multiplier </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">pad_x</span></code>: Padding sizes x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">pad_y</span></code>: Padding sizes y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride_x</span></code>: Convolution stride along the width </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride_y</span></code>: Convolution stride along the height </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dilation_x</span></code>: Dilation along width. Not used and intended for future enhancement. </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dilation_y</span></code>: Dilation along height. Not used and intended for future enhancement. </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias</span></code>: Pointer to optional bias values. If no bias is available, NULL is expected </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_offset</span></code>: Input tensor zero offset </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_offset</span></code>: Kernel tensor zero offset </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_offset</span></code>: Output tensor zero offset </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">output</span></code>: Pointer to output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_x</span></code>: Width of output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_y</span></code>: Height of output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_activation_min</span></code>: Minimum value to clamp the output to. Range : {0, 255} </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_activation_max</span></code>: Minimum value to clamp the output to. Range : {0, 255} </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_shift</span></code>: Amount of right-shift for output </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_mult</span></code>: Output multiplier for requantization </p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv431riscv_depthwise_conv_wrapper_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t">
<span id="_CPPv331riscv_depthwise_conv_wrapper_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span id="_CPPv231riscv_depthwise_conv_wrapper_s8PK16nmsis_nn_contextPK23nmsis_nn_dw_conv_paramsPK33nmsis_nn_per_channel_quant_paramsPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK4q7_tPK13nmsis_nn_dimsPK7int32_tPK13nmsis_nn_dimsP4q7_t"></span><span class="target" id="group__NNConv_1gadd730f9b8a5497148c7441b28461c0c6"></span>riscv_status <code class="sig-name descname">riscv_depthwise_conv_wrapper_s8</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_context *<em>ctx</em>, <em class="property">const</em> nmsis_nn_dw_conv_params *<em>dw_conv_params</em>, <em class="property">const</em> nmsis_nn_per_channel_quant_params *<em>quant_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> q7_t *<em>input_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> q7_t *<em>filter_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>bias_dims</em>, <em class="property">const</em> int32_t *<em>bias_data</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em>, q7_t *<em>output_data</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Wrapper function to pick the right optimized s8 depthwise convolution function. </p>
<p><ul class="simple">
<li><p>Supported framework: TensorFlow Lite</p></li>
<li><p>Picks one of the the following functions<ol class="arabic simple">
<li><p>riscv_depthwise_conv_s8()</p></li>
<li><p>riscv_depthwise_conv_3x3_s8() - RISC-V CPUs with DSP extension only</p></li>
<li><p>riscv_depthwise_conv_s8_opt()</p></li>
</ol>
</p></li>
<li><p>q7 is used as data type eventhough it is s8 data. It is done so to be consistent with existing APIs.</p></li>
<li><p>Check details of riscv_depthwise_conv_s8_opt() for potential data that can be accessed outside of the boundary. </p></li>
</ul>
<dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> - Successful completion.</p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">ctx</span></code>: Function context (e.g. temporary buffer). Check the function definition file to see if an additional buffer is required. Optional function {API}_get_buffer_size() provides the buffer size if required. </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dw_conv_params</span></code>: Depthwise convolution parameters (e.g. strides, dilations, pads,…) dw_conv_params-&gt;dilation is not used. Range of dw_conv_params-&gt;input_offset : [-127, 128] Range of dw_conv_params-&gt;output_offset : [-128, 127] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">quant_params</span></code>: Per-channel quantization info. It contains the multiplier and shift values to be applied to each output channel </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_dims</span></code>: Input (activation) tensor dimensions. Format: [H, W, C_IN] Batch argument N is not used and assumed to be 1. </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_data</span></code>: Input (activation) data pointer. Data type: int8 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_dims</span></code>: Filter tensor dimensions. Format: [1, H, W, C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_data</span></code>: Filter data pointer. Data type: int8 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_dims</span></code>: Bias tensor dimensions. Format: [C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_data</span></code>: Bias data pointer. Data type: int32 </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_dims</span></code>: Output tensor dimensions. Format: [1, H, W, C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">output_data</span></code>: Output data pointer. Data type: int8 </p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv447riscv_depthwise_conv_wrapper_s8_get_buffer_sizePK23nmsis_nn_dw_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims">
<span id="_CPPv347riscv_depthwise_conv_wrapper_s8_get_buffer_sizePK23nmsis_nn_dw_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span id="_CPPv247riscv_depthwise_conv_wrapper_s8_get_buffer_sizePK23nmsis_nn_dw_conv_paramsPK13nmsis_nn_dimsPK13nmsis_nn_dimsPK13nmsis_nn_dims"></span><span class="target" id="group__NNConv_1ga6ef29f06fe7ad6af657dadc07f49ba2c"></span>int32_t <code class="sig-name descname">riscv_depthwise_conv_wrapper_s8_get_buffer_size</code><span class="sig-paren">(</span><em class="property">const</em> nmsis_nn_dw_conv_params *<em>dw_conv_params</em>, <em class="property">const</em> nmsis_nn_dims *<em>input_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>filter_dims</em>, <em class="property">const</em> nmsis_nn_dims *<em>output_dims</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Get size of additional buffer required by riscv_depthwise_conv_wrapper_s8() </p>
<p><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>Size of additional memory required for optimizations in bytes. </p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dw_conv_params</span></code>: Depthwise convolution parameters (e.g. strides, dilations, pads,…) dw_conv_params-&gt;dilation is not used. Range of dw_conv_params-&gt;input_offset : [-127, 128] Range of dw_conv_params-&gt;input_offset : [-128, 127] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">input_dims</span></code>: Input (activation) tensor dimensions. Format: [H, W, C_IN] Batch argument N is not used and assumed to be 1. </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">filter_dims</span></code>: Filter tensor dimensions. Format: [1, H, W, C_OUT] </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">output_dims</span></code>: Output tensor dimensions. Format: [1, H, W, C_OUT] </p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

<dl class="function">
<dt id="_CPPv437riscv_depthwise_separable_conv_HWC_q7PK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv337riscv_depthwise_separable_conv_HWC_q7PK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv237riscv_depthwise_separable_conv_HWC_q7PK4q7_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tP5q15_tP4q7_t"></span><span class="target" id="group__NNConv_1ga73a880af4ffcae5ba0229a20890b05d4"></span>riscv_status <code class="sig-name descname">riscv_depthwise_separable_conv_HWC_q7</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel</em>, <em class="property">const</em> uint16_t <em>padding</em>, <em class="property">const</em> uint16_t <em>stride</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Q7 depthwise separable convolution function. </p>
<p><strong>Buffer size:</strong><dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns either <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> or <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> based on the outcome of size checking.</p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">Im_in</span></code>: pointer to input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in</span></code>: input tensor dimension </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_in</span></code>: number of input tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">wt</span></code>: pointer to kernel weights </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_out</span></code>: number of filters, i.e., output tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel</span></code>: filter kernel size </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding</span></code>: padding sizes </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride</span></code>: convolution stride </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias</span></code>: pointer to bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_shift</span></code>: amount of left-shift for bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">out_shift</span></code>: amount of right-shift for output </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">Im_out</span></code>: pointer to output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out</span></code>: output tensor dimension </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferA</span></code>: pointer to buffer space for input </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferB</span></code>: pointer to buffer space for output </p></li>
</ul>
</dd>
</dl>
</p>
<p>bufferA size: 2*ch_im_in*dim_kernel*dim_kernel</p>
<p>bufferB size: 0</p>
<p><strong>Input dimension constraints:</strong></p>
<p>ch_im_in equals ch_im_out</p>
<p>Implementation: There are 3 nested loop here: Inner loop: calculate each output value with MAC instruction over an accumulator Mid loop: loop over different output channel Outer loop: loop over different output (x, y) </p>
</dd></dl>

<dl class="function">
<dt id="_CPPv447riscv_depthwise_separable_conv_HWC_q7_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t">
<span id="_CPPv347riscv_depthwise_separable_conv_HWC_q7_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span id="_CPPv247riscv_depthwise_separable_conv_HWC_q7_nonsquarePK4q7_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tK8uint16_tPK4q7_tK8uint16_tK8uint16_tP4q7_tK8uint16_tK8uint16_tP5q15_tP4q7_t"></span><span class="target" id="group__NNConv_1gaec2d2b8c1536a08db1811d8971f20f66"></span>riscv_status <code class="sig-name descname">riscv_depthwise_separable_conv_HWC_q7_nonsquare</code><span class="sig-paren">(</span><em class="property">const</em> q7_t *<em>Im_in</em>, <em class="property">const</em> uint16_t <em>dim_im_in_x</em>, <em class="property">const</em> uint16_t <em>dim_im_in_y</em>, <em class="property">const</em> uint16_t <em>ch_im_in</em>, <em class="property">const</em> q7_t *<em>wt</em>, <em class="property">const</em> uint16_t <em>ch_im_out</em>, <em class="property">const</em> uint16_t <em>dim_kernel_x</em>, <em class="property">const</em> uint16_t <em>dim_kernel_y</em>, <em class="property">const</em> uint16_t <em>padding_x</em>, <em class="property">const</em> uint16_t <em>padding_y</em>, <em class="property">const</em> uint16_t <em>stride_x</em>, <em class="property">const</em> uint16_t <em>stride_y</em>, <em class="property">const</em> q7_t *<em>bias</em>, <em class="property">const</em> uint16_t <em>bias_shift</em>, <em class="property">const</em> uint16_t <em>out_shift</em>, q7_t *<em>Im_out</em>, <em class="property">const</em> uint16_t <em>dim_im_out_x</em>, <em class="property">const</em> uint16_t <em>dim_im_out_y</em>, q15_t *<em>bufferA</em>, q7_t *<em>bufferB</em><span class="sig-paren">)</span><br /></dt>
<dd><p>Q7 depthwise separable convolution function (non-square shape) </p>
<p><p>This function is the version with full list of optimization tricks, but with some constraints: ch_im_in is equal to ch_im_out </p>
<dl class="simple">
<dt><strong>Return</strong></dt><dd><p>The function returns either <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SIZE_MISMATCH</span></code> or <code class="docutils literal notranslate"><span class="pre">RISCV_MATH_SUCCESS</span></code> based on the outcome of size checking.</p>
</dd>
<dt><strong>Parameters</strong></dt><dd><ul class="breatheparameterlist simple">
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">Im_in</span></code>: pointer to input tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in_x</span></code>: input tensor dimension x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_in_y</span></code>: input tensor dimension y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_in</span></code>: number of input tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">wt</span></code>: pointer to kernel weights </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">ch_im_out</span></code>: number of filters, i.e., output tensor channels </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel_x</span></code>: filter kernel size x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_kernel_y</span></code>: filter kernel size y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding_x</span></code>: padding sizes x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">padding_y</span></code>: padding sizes y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride_x</span></code>: convolution stride x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">stride_y</span></code>: convolution stride y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias</span></code>: pointer to bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">bias_shift</span></code>: amount of left-shift for bias </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">out_shift</span></code>: amount of right-shift for output </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">Im_out</span></code>: pointer to output tensor </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out_x</span></code>: output tensor dimension x </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[in]</span> <span class="pre">dim_im_out_y</span></code>: output tensor dimension y </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferA</span></code>: pointer to buffer space for input </p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">[inout]</span> <span class="pre">bufferB</span></code>: pointer to buffer space for output </p></li>
</ul>
</dd>
</dl>
</p>
</dd></dl>

</div>
</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="api_fc.html" class="btn btn-neutral float-right" title="Fully-connected Layer Functions" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="api_concatenation.html" class="btn btn-neutral float-left" title="Concatenation Functions" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019-Present, Nuclei
      <span class="lastupdated">
        Last updated on Aug 10, 2021.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>